# 第 6 章 深层 `BNN` 研究综述

[Hao Wang](https://www.google.com/url?q=http://www.wanghao.in&sa=D&ust=1595195435875000&usg=AOvVaw3I4lmPqmkH08NZ12iOb1xN)， [Dit-Yan Yeung](https://www.google.com/url?q=https://www.cse.ust.hk/~dyyeung/&sa=D&ust=1595195435875000&usg=AOvVaw2fLKlN2b0ErbskC-Gnq1-O)

Massachusetts Institute of Technology

Hong Kong University of Science and Technology

【摘要】一个全面的人工智能系统不仅需要感知环境，还需要推断关系（甚至因果）及其不确定性。过去十年中，深度学习在感知任务中取得了重大进展，例如：用于视觉对象识别和语音识别。但对更高级的推断任务而言，具有贝叶斯性质的概率图模型（Probabilistic Graphical Model，`概率图模型`）则更强大和灵活。近年，贝叶斯深度学习作为统一的概率框架出现，将深度学习和贝叶斯模型紧密结合在一起，用深度学习对文本、图像的感知能力来提高进一步推断的性能，反过来，通过推断过程的反馈来增强文本或图像的感知能力。本文对贝叶斯深度学习进行了较为全面的介绍，综述了贝叶斯深度学习在推荐系统、主题模型、控制等方面的应用，并讨论了贝叶斯深度学习与神经网络的贝叶斯处理等相关课题的联系与区别。

【关键字】Deep Learning， Bayesian Networks， Probabilistic Graphical Models， Generative Models

【原文】Wang H， Yeung D Y. A survey on Bayesian deep learning[J]. ACM Computing Surveys (CSUR)， 2020， 53(5): 1-37.

【作者 blog】[wanghao.in/ `贝叶斯深度学习` .html](http://wanghao.in/ `贝叶斯深度学习` .html)

---

<style>p{text-indent:2em;2}</style>

## 6.1 概述

过去十年中，深度学习在包括视觉对象识别、文本理解和语音识别在内的许多流行感知任务中取得了巨大的成功。这些任务分别对应于人工智能系统的视觉、阅读和听觉能力，它们无疑对 AI 有效感知环境不可或缺。但构建一个实用、全面的 AI 系统，不仅需要感知，更应具备思考的能力。

以医学诊断为例，医生除了要看可见症状、医学检测数据和患者描述外，还必须寻找症状间的关系，并推断出相应病因。只有如此，医生才能为病人提供医疗建议。此例中，虽然视觉和听觉能力允许医生从病人那里获取信息，但定义医生的关键是思维部分。这里的思维能力可能涉及识别条件依赖、因果推断、逻辑推断和处理不确定性等，它们显然超出了传统深度学习方法的能力。幸运的是，另一种机器学习范式--- `概率图形模型（`概率图模型`）`---擅长概率和推断，尤其是不确定性。问题是，`概率图模型`在感知任务中效果似乎不如深度学习模型好，特别是感知任务通常涉及大规模和高维信号（如图像和视频）。为解决该问题，将深度学习和`概率图模型`统一在一个原则性概率框架内是一个自然而然的选择，即`贝叶斯深度学习（Bayesian Deep Learning，贝叶斯深度学习 ）` 。

上例中，感知任务涉及感知患者的症状（例如，通过查看医学图像），而推断任务涉及处理条件依赖、因果推断、逻辑推断和不确定性。通过贝叶斯深度学习中的原则性集成，感知任务和推断任务被视为一个整体，相互受益。既能够看到医学图像帮助医生进行诊断和推断，也能看到诊断和推断反过来帮助理解医学图像。假设医生不确定医学图像中的黑斑是什么，但如果她能够推断出病因，则可以帮她更好地决定黑斑是不是肿瘤。

再以推荐系统 `[1，70，71，92，121]` 为例。高精度推荐系统需要：（1）完整理解项目内容（例如，文档和电影中的内容）`[85]` ，（2）仔细分析用户档案和偏好 `[126，130，134]`；（3）正确评估用户间的相似性 `[3，12，46，109]` 。深度学习具有高效处理密集高维数据（如电影内容）的能力，因此擅长于任务一，而`概率图模型`对用户、项目和评级之间的条件依赖关系进行建模，则擅长于任务二和任务三。因此，将两者统一在一个概率框架中可以让我们两全其美。这种整合还带来额外好处，即推荐过程中的不确定性可以得到优雅的处理。更重要的，还可以推导出具体模型的贝叶斯处理方法，从而得到更可靠的预测 `[68，121]` 。

第三个示例是控制系统，考虑依据摄像机的实时视频流来控制复杂的动态系统。该问题可转化为迭代地执行两个任务：原始图像感知和动态模型控制。处理原始图像的感知任务可通过深度学习来实现，而控制任务通常需要更复杂的模型，如隐马尔可夫模型和卡尔曼滤波器 `[35，74]` 。通过控制模型选择的动作可以影响接收到的视频流，并进一步完成反馈循环。为在感知任务和控制任务之间实现有效迭代过程，需要信息在它们之间来回流动。感知组件将是控制组件估计其状态的基础，具有内置动态模型的控制组件将能够预测未来的轨迹（图像）。因此，采用贝叶斯深度学习解决此问题比较合适 `[125]` 。同样，在该概率框架下可以自然地处理来自原始图像的噪声和控制过程中的不确定性。

上面的例子展示了贝叶斯深度学习的主要优势：

**优势 1：感知任务和推断任务之间的信息交换；**

**优势 2：对高维数据的条件依赖；**

**优势 3：对不确定性的有效建模；**

**优势 4：隐式正则化。**

其中，在不确定性方面，贝叶斯深度学习应用于复杂任务时，有三种参数不确定性需要考虑：

（1）神经网络的参数的不确定性；
（2）与任务相关的参数的不确定性；
（3）感知部分和任务部分信息传递的不确定性。

通过使用概率分布而不是点估计来表示未知参数， `贝叶斯深度学习` 提供了一个很有前途的框架来统一处理上述不确定性。特别是，第三种不确定性只能在 `贝叶斯深度学习` 这样的统一框架下处理，因为分别训练感知组件和任务组件相当于假设两者之间交换信息时不存在不确定性。另外，神经网络在使用时存在过度参数化的问题，因此如何高效处理如此庞大的参数空间的不确定性，是一个比较大的挑战。此外，概率图模型通常更简洁，参数空间更小，从而可以提供更好的可解释性。

在正则化方面，贝叶斯深度学习具备内置 `隐式正则化` 的优点。通过对隐藏单元、神经网络参数或指定条件依赖关系的模型参数施加先验， `贝叶斯深度学习` 可在一定程度上避免过拟合，特别是在数据不足的情况下。通常， `贝叶斯深度学习模型` 中的感知组件是某种类型神经网络的贝叶斯公式，任务组件使用`概率图模型`描述不同隐藏或可观测变量之间的关系，正则化对它们都至关重要。对于感知部分，正则化技术（如权重衰减和 Dropout `[103]`） 被证明在改善神经网络性能方面是非常有效的，并且都有合理的贝叶斯解释 `[22]`。对于任务部分，专家知识或先验信息作为一种规则化，在数据稀缺的情况下，可通过施加先验信息来指导模型。

当然，将 `贝叶斯深度学习` 应用于实际任务时也存在挑战。

**挑战 1： 设计一个具有合理时间复杂度的有效贝叶斯神经网络模型非常重要。**
- 这项工作是由 `[42，72，80]` 开创的，但由于缺乏可伸缩性，并没有被广泛采用。幸运的是，最近在此方向上的一些进展 `[2，9，31，39，58,119,121]` 似乎揭示了贝叶斯神经网络的实际应用。

**挑战 2：确保感知组件和任务组件之间高效和有效的信息交换。**
- 理想情况下，一阶和二阶信息（例如，均值和方差）应该能够在两个分量之间来回流动。一种自然的想法是将感知部分表示为`概率图模型`的组成部分，并将其无缝连接到特定任务的`概率图模型`，如 `[24,118,121]` 中所做的那样。

本文提供了对 `贝叶斯深度学习` 的全面概述，并为各种应用提供了具体模型。文章其余部分安排如下：第 2 节回顾了一些基本的深度学习模型；第 3 节介绍了`概率图模型`的主要概念和技术；第 4 节将阐述统一 `贝叶斯深度学习` 框架的基本原理，并详细说明实现其感知组件和任务组件的选择；第 5 节回顾了应用于推荐系统、主题模型和控制等多个领域的 `贝叶斯深度学习模型` ，分别展示了 `贝叶斯深度学习` 在监督学习、非监督学习和一般表征学习中的作用；第 6 节对未来研究问题进行了讨论，并对全文进行了总结。

## 6.2 深度学习

深度学习通常指两层以上的神经网络。为更好地理解深度学习，我们从最简单的神经网络---多层感知机 ( `MLP` ) 开始，说明传统深度学习的工作原理。之后，回顾基于 `MLP` 的其他几种深度学习模型。本节主要介绍经典的 `MLP` 、 `AutoEncoder` 、 `CNN` 、 `RNN` 等深度学习方法。
### 6.2.1 多层感知机（ `MLP` ）

多层感知机本质上是一系列参数化的非线性变换。假设要训练一个多层感知机来执行将 $M$ 维向量映射到 $D$ 维向量的回归任务。将输入表示为矩阵 $X_0$ ( 0 表示感知机的第 0 层）。$X_0$ 的第 $j$ 行，表示为 $X_{0，j∗}$，代表一个数据点的 $M$ 维行向量。目标输出表示为 $Y$ 。类似地，$Y_{j∗}$ 表示 $D$ 维行向量。$L$ 层感知机的学习问题可表示为以下优化问题：

$$
\begin{array}{c}
\min \limits_{\left\{\mathbf{W}_{l}\right\},\left\{\mathbf{b}_{l}\right\}}\left\|\mathbf{X}_{L}-\mathrm{Y}\right\|_{F}+\lambda \sum_{l}\left\|\mathbf{W}_{l}\right\|_{F}^{2} \\\\
\text { subject to } \mathrm{X}_{l}=\sigma\left(\mathbf{X}_{l-1} \mathbf{W}_{l}+\mathbf{b}_{l}\right), l=1, \ldots, L-1 \\\\
\mathbf{X}_{L}=\mathbf{X}_{L-1} \mathbf{W}_{L}+\mathbf{b}_{L}
\end{array}
$$

其中 $σ(·)$ 是矩阵的逐元素 `Sigmoid 函数`，$σ(X)=\frac{1}{1+exp(−x)}$ 。$||·||_F$ 表示 `Frobenius` 范数。施加 $σ(·)$ 的目的是允许非线性变换。通常可用 $tanh(X)$ 和 $max(0，x)$ 等其他变换作为 `Sigmoid 函数` 的替代。

这里 $X_l(l=1,2,...,L−1)$ 是隐藏单元。一旦给定 $X_0$、$W_l$和 $B_l$ 值，就可以很容易地计算 $X_L$ 。因为 $X_0$ 是给定输入，所以只需学习 $W_l$ 和 $b_l$。学习过程使用返向传播和随机梯度下降来完成，关键是计算目标函数相对于 $W_l$ 和 $b_l$ 的梯度。如果将目标函数值表示为 $E$，则可使用链式法则计算梯度：

$$
\begin{array}{l}
\frac{\partial E}{\partial \mathbf{X}_{L}}=2\left(\mathbf{X}_{L}-\mathbf{Y}\right), \quad \frac{\partial E}{\partial \mathbf{X}_{l}}=\left(\frac{\partial E}{\partial \mathbf{X}_{l+1}} \circ \mathbf{X}_{l+1} \circ\left(1-\mathbf{X}_{l+1}\right)\right) \mathbf{W}_{l+1} \\\\
\frac{\partial E}{\partial \mathbf{W}_{l}}=\mathbf{X}_{l-1}^{T}\left(\frac{\partial E}{\partial \mathbf{X}_{l}} \circ \mathbf{X}_{l} \circ\left(1-\mathbf{X}_{l}\right)\right), \quad \frac{\partial E}{\partial \mathbf{b}_{l}}=\operatorname{mean}\left(\frac{\partial E}{\partial \mathbf{X}_{l}} \circ \mathbf{X}_{l} \circ\left(1-\mathbf{X}_{l}\right), 1\right)
\end{array}
$$

上式省略了正则化项，$l=1,...L$。$\circ$ 表示逐元素乘，$mean(·,1)$ 是 `matlab` 中的矩阵运算操作。实际上，只使用一小部分数据（例如 128 个数据点）来计算每次更新的梯度，这称为（小批量）随机梯度下降。

在传统深度学习模型中，只有 $W_l$ 、 $b_l$ 是自由参数，会在优化的每一次迭代中被更新，而 $X_l$ 不是自由参数，因为如果给定 $W_l$ 和 $b_l$，$X_l$就可以被精确计算出来。

### 6.2.2 自编码器（ `Autoencoder`）

自编码器 (`AE`) 是一种前馈神经网络，它将输入编码成更紧凑的表示，并用学习到的表示重建输入。在最简单的形式下，自编码器只不过是一个中间有瓶颈层（具有少量隐藏单元的层）的多层感知机。自编码器的概念已存在了几十年 [10，29，43，63]，并已提出了丰富的自编码器变体来增强表示学习，包括稀疏自编码器[88]、对比自编码器[93] 和去噪自编码器[111]。更多细节请参考最近出版的深度学习书籍 [29]。在这里，我们介绍了一种多层去噪自编码器，也被称为`堆叠去噪自编码器 (SDAE) `。`堆叠去噪自编码器 (SDAE)`既是自编码器的一个变体，也是其 `贝叶斯深度学习` 推荐系统中的一种应用。

`堆叠去噪自编码器 (SDAE)`[111] 是一个前馈神经网络，通过预测干净输入自身来学习带噪声输入数据的表示（编码），如图 1（左）所示。中间的隐藏层 $X_2$ 为学习紧凑表示的瓶颈层。`堆叠去噪自编码器 (SDAE)`与传统 `AE` 之间的区别在于：`堆叠去噪自编码器 (SDAE)`的输入层 $X_0$ 是净输入数据 $X_c$ 的损坏版本。`堆叠去噪自编码器 (SDAE)`本质上解决了以下优化问题：

$$
\begin{array}{c}
\min \limits_{\left\{\mathbf{W}_{l}\right\},\left\{\mathbf{b}_{l}\right\}}\left\|\mathbf{X}_{c}-\mathbf{X}_{L}\right\|_{F}^{2}+\lambda \sum_{l}\left\|\mathbf{W}_{l}\right\|_{F}^{2} \\\\
\text { subject to } \mathbf{X}_{l}=\sigma\left(\mathbf{X}_{l-1} \mathbf{W}_{l}+\mathbf{b}_{l}\right), l=1, \ldots, L-1 \\\\
\mathbf{X}_{L}=\mathbf{X}_{L-1} \mathbf{W}_{L}+\mathbf{b}_{L}
\end{array}
$$

其中 $λ$ 是正则化参数。`堆叠去噪自编码器 (SDAE)`可被视为上节描述的回归任务多层感知机。 `MLP` 的输入 $X_0$ 是原始数据 $X_c$ 的损坏版本，而目标输出 $Y$ 是原始数据的干净版本。例如，$X_c$ 可以是原始数据矩阵，可以将 $X_c$ 中 `30%` 的项目随机设置为 `0` 并得到 $X_0$。简言之，`堆叠去噪自编码器 (SDAE)`学习了一个神经网络，该神经网络将噪声数据作为输入，并在最后一层恢复干净的数据。这就是“去噪”的意思。通常，中间的瓶颈层（即图 1 中的 $X_2$) 输出将用于紧凑地表示数据。

![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210623112723_21.webp)

图 1. 左：$L=4$ 的两层`堆叠去噪自编码器 (SDAE)`。右：一个有 4 个输入特征图和 2 个输出特征图的卷积层。

### 6.2.3 卷积神经网络（ `CNN` ）

卷积神经网络 ( `CNN` ) 可以看作是 `MLP` 的另一种变体。与最初设计用于执行降维的 `AE` 不同， `CNN` 受仿生学启发。根据 [53] 的说法，猫的视皮层中已经识别出两种类型的细胞。一种是简单细胞，在其感受野内对特定模式做出最大反应，另一种是复杂细胞，其感受野较大，且被认为具有模式所在位置的局部不变性。受这些发现启发， `CNN` 提出了两个关键概念：`卷积（Convolution）` 和 `最大值池化（Max-pooling）`。

（1）卷积

在 `CNN` 中，特征图是输入图和线性滤波器卷积的结果，其后是一些基于元素的非线性变换。此处输入可以是原始图，也可以是上一层输出的特征图。具体地说，利用输入 $X$ 、权重 $W^k$、偏置 $b^k$，可以计算得到第 $k$ 层特征图 $H^k$ ：

$$
\mathbf{H}_{i j}^{k}=\tanh \left(\left(\mathbf{W}^{k} * \mathbf{X}\right)_{i j}+b^{k}\right)
$$

注意，上式假设一个输入特征图和多个输出特征图。在实践中，由于 `CNN` 的深层结构，通常还会有多个输入特征图，如图 1 （右）所示的具有 4 个输入特征图和 2 个输出特征图的卷积层。

（2）最大值池化

传统 `CNN` 中的卷积层之后是最大值池化层，这可被视为一种非线性下采样。最大值池化的操作非常简单，例如，如果有一个大小为 $6×9$ 的特征图，则与 $3×3$ 邻域的最大值池化结果将是一个大小为 $2×3$ 的下采样特征图。下采样特征图的每个元素都是 $6×9$ 特征图中对应元素的 $3×3$ 邻域中的最大值。最大值池化层不仅可忽略非最大项目，降低计算开销，而且可提供局部的平移不变性。

（3）把所有这些放在一起

通常为形成一个完整有效的 `CNN` ，在进入 `MLP` 进行分类或回归等任务之前，输入将在卷积层和池化层之间交替。经典的例子是 LeNet-5[64]，它在进入目标任务的全连接 `MLP` 之前，在 2 个卷积层和池化层之间交替。

### 6.2.4 循环神经网络（ `RNN` ）

在阅读文章时，人们通常一次只读一个词，并试图根据之前的词来理解当前词，这是一个需要短期记忆的循环过程。不幸的是，传统前馈神经网络（如图 2 左所示）无法做到这一点。例如，假设我们想要在阅读一篇文章时不断预测下一个单词，传统前馈网络仅将输出 $\mathbf{o}$ 计算为 $V_q(Wx)$ ，其中函数 $q(·)$ 表示面向元素的非线性变换，和前后的元素均无关，因此网络无法对单词序列进行建模以预测下一个单词。

![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210623112624_a8.webp)

图 2 左：具有一个隐藏层的传统前馈神经网络，其中 $\mathbf{X}$ 是输入，$\mathbf{Z}$ 是隐藏层，$\mathbf{O}$ 是输出，$W$ 和 $V$ 是相应的权重（这里省略偏置 $b$ ）。中：一个输入为 ${\mathbf{X}_t}^T_{t=1}$ ，隐藏状态为 ${h_t}^T_{t=1}$，输出为 ${\mathbf{O}_t}^T_{t=1}$ 的递归神经网络。右：展开的 `RNN` ，与图 2（中）等价。每个节点（例如，$\mathbf{x}_1$、$h_1$ 或 $\mathbf{o}_1$ ）与特定时间步相关联。

#### 2.4.1 传统的递归神经网络。

为解决该问题，需要一个递归神经网络 [29]，而不是前馈神经网络。如图 2（中间）所示，当前隐藏状态 $h_t$ 的计算取决于当前输入 $\mathbf{x}_t$（例如第 $t$ 个词）和先前的隐藏状态 $h_{t-1}$ 。这就是 `RNN` 中存在循环的原因。该循环启用了 `RNN` 中的短期记忆，$h_t$ 表示到目前为止网络在第 $t$ 个时间步知道的内容。为了更清楚地查看计算，可展开 `RNN` 循环，表示为图 2（右）。如果使用双曲正切非线性函数 （`Tanh`），则输出 $o_t$ 计算如下：

$$
\mathbf{a}_{t}=\mathbf{W h}_{t-1}+\mathbf{Y} \mathbf{x}_{t}+\mathbf{b}, \quad \mathbf{h}_{t}=\tanh \left(\mathbf{a}_{t}\right), \quad \mathbf{o}_{t}=\mathbf{V h}_{t}+\mathbf{c}
$$

其中 $Y$、$W$ 和 $V$ 分别表示输入到隐层、隐层到隐层、隐层到输出连接的权重矩阵，$b$ 和 $c$ 是相应的偏置。如果任务是在每个时间步对输入数据进行分类，则可以计算分类概率为 $p_t= \operatorname{softmax}(o_t)$，其中:

$$
\operatorname {softmax} (q) = \frac {exp(q)} {\sum \limits_i {exp(q_i)}}
$$

与前馈网络类似， `RNN` 使用一种称为时间返向传播 (BPTT) 的广义返向传播算法 [29] 进行训练。梯度本质上是通过展开的网络计算的，如 `图 2（右）`所示，所有时间步共享权重和偏置。

#### 2.4.2 门控递归神经网络

`传统 RNN` 的问题是：在多个时间步上传播的梯度很容易消失或爆炸，使优化变得非常困难。此外，由于通过 `RNN` 的信号逐层呈指数衰减，给长序列中的长期相关性建模带来困难。例如，想要预测下面这段话的最后一个词：“I have many books ... I like reading”。为得到答案，我们不仅需要 `短期记忆` ，还需要 `长期记忆` 来提取文本之前的信息（如 `books`）。为解决该问题，`长短期记忆模型 ( LSTM )` 被设计成一种 `门控 RNN` ，用于在相对较长的持续时间内建模和积累信息。 `LSTM` 背后的直觉是，当处理由几个子序列组成的序列时，神经网络在继续处理下一个子序列前总结或忘记旧状态是有用的 [29]。使用 $t=1,...,t_j$ 索引序列中的单词，则 `LSTM` 的公式如下（为简单去掉了索引 $j$ ）：

$$
\mathbf{x}_{t}=\mathbf{W}_{w} \mathbf{e}_{t}, \quad \mathbf{s}_{t}=\mathbf{h}_{t-1}^{f} \odot \mathbf{s}_{t-1}+\mathbf{h}_{t-1}^{i} \odot \sigma\left(\mathbf{Y} \mathbf{x}_{t-1}+\mathbf{W h}_{t-1}+\mathbf{b}\right) \tag{式 1 }
$$

其中 $\mathbf{x}_t$ 是第 $t$ 个词的词嵌入，$W_w$ 是一个 $K_W-by-S$ 的词嵌入矩阵，$e_t$ 是 $1-of-S$ 的表示，$⊙$ 表示两个向量之间的元素级乘积运算（点积），$σ(·)$ 表示 `Sigmoid 函数`，$s_t$ 表示第 $t$ 个词的单元状态，以及 $b$、$Y$ 和 $W$ 分别表示偏置、输入权重和递归权重。可以根据下式，使用其相应的权重和偏置 $Y^f$、$W^f$、$Y^i$、$W^i$、$b^f$ 和 $b^i$ 来计算遗忘门单元 $h_t^f$ 和输入门单元 $h^i_t$ ：

$$
\mathbf{h}_{t}^{f}=\sigma\left(\mathrm{Y}^{f} \mathbf{x}_{t}+\mathbf{W}^{f} \mathbf{h}_{t}+\mathbf{b}^{f}\right), \quad \mathbf{h}_{t}^{i}=\sigma\left(\mathbf{Y}^{i} \mathbf{x}_{t}+\mathbf{W}^{i} \mathbf{h}_{t}+\mathbf{b}^{i}\right)
$$

输出取决于具有自身权重和偏置 $Y^o$、$W^o$ 和 $b^o$ 的输出门 $h_t^o$：

$$
\mathbf{h}_{t}=\tanh \left(\mathbf{s}_{t}\right) \odot \mathbf{h}_{t-1}^{o}, \quad \mathbf{h}_{t}^{o}=\sigma\left(\mathbf{Y}^{o} \mathbf{x}_{t}+\mathbf{W}^{o} \mathbf{h}_{t}+\mathbf{b}^{o}\right)
$$

注意，在 `LSTM` 中，处理后序列的信息包含在单元状态 $s_t$ 和输出状态 $h_t$ 的单元状态中，这两个状态都是长度为 $K_W$ 的列向量。

类似于 [16,108]，可以使用第一个 `LSTM` 的最后一个时间步的输出状态和单元状态 （$h_{T_j}$ 和 $s_{T_j}$） 作为第二个 `LSTM` 的初始输出状态和单元状态。这样两个 `LSTM` 就可以串联起来，形成`编码器-解码器`体系结构，如图 3 所示。

注意，有大量关于深度学习和神经网络的文献。本部分介绍仅作为贝叶斯深度学习的背景。读者请参考 [29]，以获得更多细节。

![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210623113251_b0.webp)

图 3 包含两个 `LSTM` 的`编码器-解码器`架构。`编码器 LSTM` （左边矩形框中）将序列 `ABC` 编码成一个表示，而`解码器 LSTM` （右边矩形框中）从表示中恢复序列。“$”标记句子的结尾。

## 6.3 概率图模型

`概率图形模型（Probabilistic Graphical Models，PGM）`使用图形表示法来描述随机变量及其之间的关系。与包含节点和边的图类似，`概率图模型`具有表示随机变量的节点和表示它们间概率关系的边。

### 6.3.1 主要模型

`概率图模型`有两种基本类型，`有向概率图模型`（历史遗留下来也称为`贝叶斯网络`，注意与贝叶斯神经网络的区别）和无向 概率图模型（也称为马尔可夫随机场） `[5]`。本文主要关注`有向概率图模型`，有关`无向概率图模型`的详细信息，请参阅 `[5]`。

`概率图模型`的一个经典例子是潜狄拉克雷分配（Latent Dirichlet Allocation， `LDA` ），被用于对文档中单词和主题的生成关系建模 `[8]` 。通常，`概率图模型`带有模型的图形化表示和一个生成过程，用来描述随机变量是如何一步一步产生的。

图 4 显示了 `LDA` 的概率图模型，相应生成过程如下：

对于每个文档 $j(j \in \{ 1,2, \ldots, J\})$ ，

（1） 该样本集的主题概率抽自狄拉克雷分布： $\theta_{j} \sim \operatorname{Dirichlet}(\alpha)$ 。 

（2） 对于第 $j$ 个文档 $\mathbf{w}_j$ ，其中的每个词 $w_{j_n}$ ，

 （a）单词的主题抽自 $\theta_j$ 的多项分布 $z_{j_n} \sim \operatorname{Mult}\left(\theta_{j}\right)$ 。

 （b）单词抽自 $\beta_{z_{j_n}}$ 的多项分布 $w_{j_n} \sim \operatorname{Mult}\left(\beta_{z_{j_n}}\right)$ 。

上述生成过程提供了随机变量的生成信息。图 4 的概率图模型中，阴影节点表示可观测随机变量，其他节点为隐变量 （ $\theta$ 和 $z$ ）或参数（ $\alpha$ 和 $\beta$ ）。一旦定义了模型，就可以应用学习算法自动学习这些隐变量和参数。

![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210519163118fb.webp)

图 4 `LDA` 的概率图模型，$J$ 是文档数，$D$ 是文档中的词数，$K$ 是主题数量。

由于其贝叶斯性质，诸如 `LDA` 的概率图模型很容易扩展以合并更多信息或执行其他任务。例如，在 `LDA` 后提出了主题模型的不同变体，`[7,113]` 建议纳入时间信息，`[6]` 假设了主题之间的相关性并扩展了 `LDA` 。`[44]` 将 `LDA` 从批处理模式扩展为在线处理，从而可处理大型数据集。在推荐系统领域，`协同主题回归 ( CTR ) [112]` 扩展了 `LDA` 以纳入评级信息，该模型被进一步扩展以包含社交信息 `[89,115,116]` 。

### 6.3.2 学习与推断

**严格地说，查找参数（如图 4 中的 $\alpha$ 和 $\beta$ ) 的过程称为学习，查找给定参数的隐变量（如图 4 中的 $\theta$ 和 $z$ ) 的过程称为推断。**

然而，如果只给出可观测变量（如图 4 中的 $w$ ）时，学习和推断往往是交织在一起的。例如 `LDA` 的学习和推断会在隐变量更新（对应于推断过程）和参数更新（对应于学习过程）之间交替进行。一旦学习和推断完成，就可学习得到参数 $\alpha$ 和 $\beta$ 。如果有新文档到来，就可以固定 $\alpha$ 和 $\beta$ ，然后单独执行推断以找到新文档的主题概率 $\theta_J$ 。

与 `LDA` 类似，每种概率图模型都有各种学习和推断算法可用。其中，最具成本效益的方法可能是最大后验概率（ `MAP` ），它相当于将隐变量的后验概率最大化。使用 `MAP` ，学习过程等同于用正则化最小化（或最大化）目标函数。一个著名的例子是 `概率矩阵分解 (PMF)[96]`，其中概率图模型的学习等价于用 $L2$ 正则化将一个大矩阵分解成两个低秩矩阵。

尽管 `MAP` 效率很高，但它仅能给出隐变量和参数的点估计。为将不确定性纳入考虑以充分利用贝叶斯模型优势，人们不得不求助于一些贝叶斯计算，如 `变分推断` 和 `MCMC` 。例如，原始的 `LDA` 使用 `变分推断` 来获得近似真实分布的后验分布 `[8]` 。隐变量和参数的学习则归结为最小化 `变分分布` 和 `真实后验分布` 之间的 `KL 散度`。除 `变分推断` 外，贝叶斯计算的另一选择是 `马尔科夫链蒙特卡洛方法（MCMC）` 。例如， `[86]`已提出了学习 `LDA` 后验分布的 `MCMC`方法。

```{note}
注： 概率图模型推断任务大致可分为两类：概率推断任务（求概率分布）和最大后验推断任务（求变量值）。概率推断任务主要用于推断得到随机变量的联合概率，进而在联合概率分布基础上计算边缘概率分布或条件概率分布，是一种生成式任务，常用方法有`变量消除法`、`信念传播法`、`变分法`、 `MCMC方法` 等。最大后验推断任务则寻求使得后验联合概率最大化的变量值，是一种判别式任务，常用方法有`经最大化改造后的变量消除法`、`团树传播法`、`返向传播法`等。
```

## 6.4 贝叶斯深度学习

在这节中，将列出一些最新的 `贝叶斯深度学习模型`，它们在推荐系统、主题模型、控制等方面都有应用。这些模型的汇总见表 1 。

表 1 具有不同学习算法（MAP -- 最大后验概率；VI -- 变分推断；Hybrid MC -- 混合蒙特卡罗）和不同方差类型（ZV -- 零方差； HV -- 超方差；LV -- 可学习方差）的 `贝叶斯深度学习模型` 汇总。

![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210623140020_c3.webp)

### 6.4.1 贝叶斯神经网络与贝叶斯深度学习简史

与 `贝叶斯深度学习` 高度相关的概念是`贝叶斯神经网络 ( BNN )` 或`神经网络的贝叶斯处理`。与其他贝叶斯处理类似， `BNN` 对神经网络的参数施加先验，目的是学习这些参数的后验分布；在推断阶段，后验分布被边缘化以产生最终预测结果。神经网络的上述贝叶斯处理过程被称为 `贝叶斯模型平均（Bayesian Model Averaging）`[5]` ，可被视为学习了无限数量的神经网络（或神经网络的分布），而后通过集成来聚合结果。

```{tip}
注：贝叶斯神经网络通过为神经网络的权重引入不确定性进行正则化（regularization）。你可以把它想象成一个集成（ensemble）了无穷多组神经网络（权重分布上的每一种可能性构成一个确定的神经网络，从此角度看，贝叶斯神经网络可以视为所有可能性的集成）的模型。
```

对 `BNN` 的研究可以追溯到 20 世纪 90 年代，经典著作始于 `[42，72，80]` 。多年来，出现了大量文献 `[2，9，31，39，58,100]` ，实现了更好的扩展，并结合了最新的深度神经网络进展。由于贝叶斯神经网络历史悠久，术语`“贝叶斯深度学习”`有时专指`“贝叶斯神经网络”`[73,128]` 。本文使用 `“贝叶斯深度学习”` 来泛指<u>包含贝叶斯神经网络在内的概率框架，在该框架下，`贝叶斯神经网络`可视为具有 `感知组件` 和 `空任务组件`的 `贝叶斯深度学习模型` 。</u>

有趣的是，虽然贝叶斯神经网络研究开始于 20 世纪 90 年代，但更广泛意义上的贝叶斯深度学习研究大约始于 2014 年 `[38,114,118,121]` ，略晚于 2012 年 ImageNet LSVRC 竞赛的深度学习突破 `[62]`。正如将在后面几节中看到的，`贝叶斯神经网络` 通常用作作 `贝叶斯深度学习模型` 中的 `感知组件`。

如今 `贝叶斯深度学习` 越来越受欢迎，已经在推荐系统、计算机视觉等领域获得了成功，并成为各种会议研讨会的主题（例如，`NeurIPS BDL Workshop 6`）。

### 6.4.2 通用贝叶斯深度学习模型架构

如 6.1 节提到的， `贝叶斯深度学习模型` 是一个原则性的概率框架，包含两个紧密集成的组件：感知组件和任务组件。

#### **（1）两个组件** 

图 5 以一个简单的 `贝叶斯深度学习模型`为例显示了其概率图模型。左侧红色矩形内的部分表示感知组件，右侧蓝色矩形内的部分表示任务组件。通常感知组件是一个具有多个非线性处理层（在`概率图模型`中表示为链结构）的深度学习模型的概率公式。一般而言，感知组件中的节点和边相对简单，而任务组件中的节点和边通常描述更复杂的变量间分布和关系。任务组件的形式多样，可以是一个`有向概率图模型`（即类似 `LDA`模型的`贝叶斯网络`） 、一个贝叶斯深度神经网络 `[117]` ，或者可以是一个随机过程 `[51，94]` 。

```{tip}
注：概率图模型分为两类，一是有向图模型，通常被称为`贝叶斯网络`，二是无向图模型，通常被称为马尔可夫随机场。因为在研究随机过程时，常假设其为马尔可夫随机场，所以此处用随机过程代指了马尔科夫随机场。
```

![图片](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_20210519120555fb.webp)
<center>

图 5 一个 `贝叶斯深度学习模型` 的概率图。左侧红色矩形表示感知组件，右侧蓝色矩形表示任务组件，铰链变量集合 $Ω_h={H}$ 。 
</center>

#### **（2）三类变量**

 `贝叶斯深度学习模型` 中有三类变量：`感知变量（perception variables）` 、 `铰链变量（hinge variables ）` 和 `任务变量（task variables ）` 。

本文使用 $Ω_p$ 表示感知变量集（例如，图 5 中的 $X_0$ 、 $X_1$ 和 $W_1$ 等），它们是感知组件中的变量。通常，$Ω_p$ 是深度学习模型的概率公式中出现的 `参数（权重）` 和 `隐变量（神经元）` 。

 $Ω_h$ 用于表示铰链变量集（如图 5 中的 $H$ ），此类变量来自于任务组件，但直接与感知组件交互。

任务变量集（如图 5 中的 $A$ 、$B$ 和 $C$ ），即任务组件中与感知组件无直接关系的变量，被表示为 $Ω_t$ 。

#### （3）有监督和无监督学习的生成式过程

如果两个组件之间的连接边指向 $Ω_h$，则依据概率图模型理论，所有变量的联合概率分布可以写为：

$$
p\left(\Omega_{p}, \Omega_{h}, \Omega_{t}\right)=p\left(\Omega_{p}\right) p\left(\Omega_{h} \mid \Omega_{p}\right) p\left(\Omega_{t} \mid \Omega_{h}\right) \tag{式 2}
$$

如果两个组件之间的连接边源自 $Ω_h $ ，则所有变量的联合概率分布可以写为：

$$
p\left(\Omega_{p}, \Omega_{h}, \Omega_{t}\right)=p\left(\Omega_{t}\right) p\left(\Omega_{h} \mid \Omega_{t}\right) p\left(\Omega_{p} \mid \Omega_{h}\right) \tag{式 3}
$$

公式 (2) 和 (3) 假设数据的生成过程不同，并对应于不同学习任务。

式 2 用于监督学习，其中感知组件充当`概率（或贝叶斯）表示学习器`，以促进任何下游任务（参见 `5.1 节`示例）。式 3 用于无监督学习，其中任务组件提供`结构约束`和`领域知识`，以帮助感知组件学习更强的表示（参见 `5.2 节`示例）。

请注意，除上述两种情况外， `贝叶斯深度学习` 还可能存在既指向 $\Omega_h$ 又源自 $\Omega_h$ 的混合边情况，此时联合分布的分解将更加复杂。

```{note}
注：上述联合概率分布基于概率图模型的推断计算。细节参见概率图模型相关理论和书籍。
```

#### （4）独立性要求

铰链变量 $Ω_h$ 和相关条件分布的引入大大简化了模型（特别是当 $Ω_h$ 的入度或出度为 1 时），便于学习，并可提供 `归纳偏置` 以聚焦 $Ω_h$ 内部的信息。但请注意，<u>铰链变量始终位于任务组件中，并且铰链变量 $Ω_h$ 和感知组件之间的连接（如图 5 中的 $X_4→H$ ）应该尽量独立，以方便感知组件实施并行计算</u>。例如，$H$ 中的每一行只与 $X_4$ 中的一个对应行相关。虽然在 `贝叶斯深度学习模型` 中这并非强制性的，但满足此要求将显著提高模型训练时的并行计算效率。

```{note}
归纳偏置（Inductive Bias）：从现实生活中观察到的现象中归纳出一定的规则，然后对模型做一定的约束，从而可以起到` “模型选择”`的作用，即从假设空间中选择出更符合现实规则的模型。归纳是自然科学中常用的两大方法（归纳与演绎，induction and deduction）之一，指从一些例子中寻找共性、泛化，并形成通用规则的过程；而偏置 （bias）指对模型的某些方面偏好，偏置从词面上看，很容易让人想到估计值与真实值的差别，从而让人误将 `归纳偏置` 视为某种需要被规避的错误或误差。但事实并非如此，归纳偏置在机器学习中通常起积极作用。

归纳偏置与贝叶斯统计中的`“先验”`有些类似，但`“归纳偏置”`更倾向于经验性假设。例如：基于样本 {（0，0）（1，1）...（i，i）...（n,n）} 学习一个 $x$ 到 $y$ 的回归模型，从数学上满足样本的映射模型有无穷多种，但在某些情况下我们会做出`“假定这是一个线性映射”`的假设，之后在此假设基础上对模型进行学习，此处`“假定这是一个线性映射”`就是基于经验知识作出的归纳偏置；而在线性映射空间进行学习时，也可能存在无限种映射，此时根据`奥卡姆剃刀原则`选择`“尽可能简单的模型”`，而`奥卡姆剃刀`是机器学习中最典型的一种归纳偏置。

注：归纳偏置是一种在模型的无限解空间中所引入的合理假设与约束，它能够缩小求解空间并提高所得模型在目标域的泛化性能。
```

#### （5） 铰链方差 $Ω_h$ 的灵活性

如`第 1 节`所述， 对`感知组件`和`任务组件`之间交换信息的不确定性建模，是贝叶斯深度学习的主要目的之一。 其本质是对与 $Ω_h$ 相关的不确定性进行建模。例如：在`式 2`中，该不确定性反映在条件概率密度 $p(Ω_h|Ω_p)$ 的方差中。

```{tip}
为简单起见，本例中假设贝叶斯深度学习模型的联合似然为`式 2`，$\Omega_p=\{p\}$ 、 $\Omega_h=\{h\}$ ， 且 $p(\Omega_h|\Omega_p)= \mathcal{N}(\mu_p，σ^2_p)$。
```

根据灵活程度， $\Omega_h$ 有三种类型的方差 ：

- `零方差（Zero-Variance，ZV）`：没有不确定性，方差为零，即假设在两个组件之间的信息交换过程中不存在不确定性。在本例中，`ZV` 表现为直接设置 $σ_p^2= 0$ 。
- `超方差（Hyper-Variance，HV）：方差大小由超参数决定，即假设信息交换期间的不确定性通过某些超参数定义。在本例中，`HV` 表现为 $σ_p^2$ 是手动调整的超参数。
- `可学习方差（Learnable Variance，LV）`，方差可通过数据学习得到，即使用可学习的参数来表示信息交换过程中的不确定性。在本例中，`LV` 表现为 $σ_p^2$ 为可学习的参数。

显然在模型灵活性方面，$LV>HV>ZV$。正常情况下，如果适当地正则化，`LV 模型` 的性能应当优于 `HV 模型` ，而 `HV 模型` 又优于 `ZV 模型` 。表 1 中显示了不同 `贝叶斯深度学习模型` 中 $\Omega_h$ 的方差类型。

请注意，尽管表中每种模型都有特定的铰链方差类型，但始终可以调整模型以设计出满足其他类型要求的模型。例如，虽然表中的 `协同深度学习`模型（Collaborative Deep Learning， `协同深度学习`）` 是 `HV` 模型，但可以很容易地调整 `协同深度学习`中的 $p(Ω_h|Ω_p)$ 来设计其对应的 `ZV` 和 `LV` 项。`[121]` 的作者比较了 `HV `协同深度学习`和 `ZV `协同深度学习`的性能，发现前者要好得多，这意味着对两个组件之间的不确定性进行建模对性能至关重要。

#### （6）学习算法

由于 `贝叶斯深度学习` 的性质，实用的学习算法需满足以下准则：

- 准则 1：应当是在线算法，以便能够很好地扩展到大数据集；

- 准则 2：应当足够有效，能够随着感知组件中的空闲参数数量线性扩展。

准则 1 暗示传统的 `变分推断` 或 `MCMC` 方法可能不适用。通常需要它们的在线版本 `[45]` 。大多数基于 SGD 的方法也不起作用，除非只执行 `MAP 推断`（与贝叶斯处理相反）。

准则 2 是必需的，因为在感知组件中通常有大量空闲参数。这意味着基于拉普拉斯近似的方法 `[72]`是不现实的，因为其涉及到海森矩阵中与自由参数数量成二次方关系的计算复杂度。

### 6.4.3 感知组件

理想情况下，感知组件应是一个贝叶斯神经网络，确保感知组件具备处理参数及输出不确定性的能力，以便与任务组件（任务组件天生是概率的）兼容。

正如 `6.4.1 节` 提到的，贝叶斯神经网络研究可追溯到 20 世纪 90 年代 `[31，42，72，80]`。但当时由于缺乏可扩展性而没有被广泛采纳。为解决此问题，最近有了一些发展，例如 `受限玻尔兹曼机 (RBM) [40，41]`、`概率广义堆叠去噪自编码器 （pSDAE） [118,121]`、`变分自编码器 (VAE)[58]`、`概率返向传播 (PBP)[39]`、`贝叶斯返向传播 (BBB)[9]` 、`贝叶斯暗知识 (BDK)[2]` 和 `自然参数网络 (NPN)[119]`。

最近，`生成性对抗网络 (GAN)[30]` 作为一种新的神经网络训练方案盛行，并在图像生成方面显示出生命力。随后，`GAN` 的贝叶斯公式（以及相关的理论结果）也被提出 `[30，37]` 。这些模型也是 `贝叶斯深度学习框架`中感知组件的潜在构建模块。

本节主要介绍最新的贝叶斯神经网络，如 `RBM`、`pSDAE` 、`VAE` 和 `NPN` 。建议读者参考 `[29]` ，了解在此方向上的早期工作。

#### （1）受限玻尔兹曼机（Restrict Boltzmann Machine，RBM）

`RBM` 是一种特殊的贝叶斯神经网络，用于学习输入随机变量的概率分布。`RBM` 具有两层神经元，其中相邻层的神经元之间全相连，同层的神经元之间无相连（此即所谓受限的定义）。其主要特点：一是没有返向传播训练，`RBM` 的返向过程是在给定激活值的情况下估计输入 $X$ 的概率，期间使用与前向传播过程相同的权重参数，可以被表达为 $p(x|a; w)$ 。，二是隐层神经元是二值的。如果这两层是更深网络的一部分，那么第一个隐藏层的输出会被传递到第二个隐藏层作为输入，进而可以有很多隐藏层，直至扩展到最终分类层。对于简单前馈网络，`RBM` 本质上起着自编码器的作用。

具体而言，`RBM` 定义了以下能量：

$$
E(\mathbf{v}, \mathbf{h})=-\mathbf{v}^{T} \mathbf{W h}-\mathbf{v}^{T} \mathbf{b}-\mathbf{h}^{T} \mathbf{a} 
$$

其中 $\mathbf{v}$ 表示可见神经元，$\mathbf{h}$ 表示二值的隐藏神经元。$W$ 、$a$ 和 $b$ 是可学习的权重参数。能量函数可推出以下条件分布：

$$
p(\mathbf{v} \mid \mathbf{h})=\frac{\exp (-E(\mathbf{v}, \mathbf{h}))}{\sum_{\mathbf{v}} \exp (-E(\mathbf{v}, \mathbf{h}))}, \quad p(\mathbf{h} \mid \mathbf{v})=\frac{\exp (-E(\mathbf{v}, \mathbf{h}))}{\sum_{\mathbf{h}} \exp (-E(\mathbf{v}, \mathbf{h}))} \tag{式 4}
$$

`RBM` 使用 `对比散度（Contrastive Divergence）”[40]` 而不是返向传播进行训练。一旦经过训练，`RBM` 就可通过边缘化其他神经元来推断 $\mathbf{h}$ 或 $\mathbf{v}$。还可以堆叠 `RBM 层`以形成 `深度信念网络 (DBN)[76]` ，使用`深度 RBN` 的多个分支进行多模态学习 `[104]`，或者将 `DBN` 与卷积层相结合以形成 `卷积 DBN [65]`。

#### （2）概率堆叠去噪自编码器（`pSDAE` ）

在`第 6.2.2 节`引入`堆叠去噪自编码器 (SDAE)`之后，如果假设干净输入 $X_c$ 和受损输入 $X_0$ 均为可观测变量，类似 `[4，5，13，72]`，可以定义`概率堆叠去噪自编码器（ pSDAE` ）的生成过程：

（1）对于 `SDAE 网络` 的每一层 $l$ 

- （a）对于权重矩阵 $W_l$ 中的列 $n$ ，抽取 $\mathbf{W}_{l,*n} \sim \mathcal{N}(0, \lambda_w^{-1} \mathbf{I}_{K_l})$ 。
- （b）抽取偏差向量 $\mathbf{b}_{l} \sim \mathcal{N}\left(0, \lambda_{w}^{-1} \mathbf{I}_{K_{l}}\right)$。
- （c）对于 $\mathrm{X}_{l}$ 中的行 $j$ ，抽取：

$$
\mathbf{X}_{l, j*} \sim \mathcal{N}\left(\sigma\left(\mathbf{X}_{l-1, j*} \mathbf{W}_{l}+\mathbf{b}_{l}\right), \lambda_{s}^{-1} \mathbf{I}_{K_{l}}\right) \tag{式 5}
$$

(2) 对于每个元素 $j$ ，抽取干净输入:

$$
\mathbf{X}_{c, j*} \sim \mathcal{N}\left(\mathbf{X}_{L, j *}, \lambda_{n}^{-1} \mathbf{I}_{B}\right)
$$

注意，如果 $λ_s$ 趋于无穷大，则公式 (5) 中的高斯分布将变成以 $σ(X_{l−1，j∗}W_l+b_l)$ 为中心的 `狄拉克增量分布 [106]`，其中 $σ(·)$ 是 `Sigmoid 函数`，并且模型将退化为普通`堆叠去噪自编码器 (SDAE)`。这是称之为 `“广义SDAE”` 的原因。

网络前 $L/2$ 层充当编码器，后 $L/2$ 层充当解码器。后验概率最大化等价于考虑权重衰减的重构误差最小化。

继 `pSDAE` 之后，其卷积版本 `[132]` 和递归版本 `[122]` 都已提出，并在知识图谱嵌入和推荐系统中得到了应用。

#### （3）变分自编码器（Variational Autoencoders，VAE）

`变分自编码器 (VAE) [58]` 本质上试图学习最大化`证据下界（ELBO）` 的参数 $ϕ$ 和 $\theta$ ：

$$
\mathcal{L}_{v a e}=E_{q_{\phi}(z \mid \mathbf{x})}\left[\log p_{\theta}(\mathbf{x} \mid \mathbf{z})\right]-K L\left(q_{\phi}(\mathbf{z} \mid \mathbf{x}) \| p(\mathbf{z})\right) \tag{式 6}
$$

其中 $q_ϕ(z|x)$ 是由 $ϕ$ 参数化的编码器，$p_\theta(x|z)$ 是由 $\theta$ 参数化的解码器。第一项的负值类似于普通自编码器中的重构误差，而 `KL 散度`作为编码器的正则化项。在训练期间，$q_ϕ(z|x)$ 将输出高斯分布的均值和方差，通过重参数化技巧从该均值和方差中采样 $z$ 。通常 $q_ϕ(z|x)$ 由具有两个分支的 `MLP` 参数化，一个分支产生平均值，另一个分支产生方差。

类似于 `pSDAE` 的情况，已经提出了多种 `VAE 变体`。例如，`重要性加权自编码器 (IWAE)[11]` 通过重要性加权得到了更紧致的下界，`[129]` 将 `LSTM` 、`VAE` 和`扩展 CNN` 结合用于文本建模，`[17]` 提出了 `VAE 的递归版本`，称为`变分 RNN (VRNN)`。

#### （4）自然参数网络（Natural-Parameter Networks，NPN）

与通常采用确定性输入的普通神经网络不同，`自然参数网络(NPN)[119]` 是一种以分布为输入的概率神经网络。输入分布通过线性和非线性变换层来产生输出分布。在 `NPN` 中，所有隐藏神经元和权值也是以封闭形式表示的分布。请注意，这与 `VAE` 不同，`VAE` 只有中间层输出 $z$ 是分布。

例如，在普通`线性 NN` 中，$f_w(x)=wx$ 将标量 $x$ 作为输入，并基于标量参数 $w$ 计算输出；而相应的`高斯 NPN` 假设 $w$ 是从高斯分布 $\mathcal{N}(w_m，w_s)$ 中抽取的样本，$x$ 是从 $\mathcal{N}(x_m，x_s)$ 中抽得（当输入确定时，$x_s$ 被设置为 0）。 $\theta=(w_m，w_s)$ 被视为可学习的参数对，`NPN` 将计算输出高斯分布的均值 $µ_\theta(x_m，x_s)$ 和方差 $s_\theta(x_m，x_s)$ （此处省略了偏差项）：

$$
\mu_{\theta}\left(x_{m}, x_{s}\right)=E[w x]=x_{m} w_{m} \tag{式 7}
$$

$$
s_{\theta}\left(x_{m}, x_{s}\right)=D[w x]=x_{s} w_{s}+x_{s} w_{m}^{2}+x_{m}^{2} w_{s} \tag{式 8}
$$

因此，该 `高斯 NPN` 的输出是表示高斯分布的元组 $(µ_\theta(x_m，x_s)，s_\theta(x_m，x_s))$ ，而不是单个值。 

如果不可用，则可将 `NPN` 的输入 $x_s$ 的方差设置为 0。请注意，由于 $s_\theta(x_m，0)=x_m^2w_s$ ，即使对于所有数据点 $x_s=0$ ， $w_m$ 和 $w_s$ 依然可学习得到。上面的推导在实践中被推广到处理向量和矩阵`[119]` 。除高斯分布外，`NPN` 还支持其他指数族分布，如泊松分布和伽马分布 `[119]`。

继 NPN 之后，提出了一个轻量级版本 `[26]`，以加快训练和推断过程。另一个变体 `MaxNPN[100]` 扩展了 `NPN` 以处理最大值池化层和分类层。`ConvNPN[87]` 启用 `NPN` 中的卷积层。在模型量化和压缩方面，`BinaryNPN[107]` 也被提出为 `NPN` 的二进制版本，以获得更好的效率。

### 6.4.4 任务组件

本节将介绍不同形式的任务组件。任务组件的目的是将概率先验知识合成到 `贝叶斯深度学习模型` 中。这样的知识可以用`概率图模型`自然地表示出来。具体地说，它可以是 `典型贝叶斯网络[5，54]` 、`双向推断网络 [117]` 或 `随机过程 [94]` 。

#### （1） 贝叶斯网络（Bayesian Network，BN）

`贝叶斯网络`是任务组件最常见的选择。正如`第 3 节`提到的，贝叶斯网络可以自然地表示条件依赖关系并处理不确定性。除上面介绍的 `LDA` 外，`概率矩阵分解 (PMF)[96]` 是一个更直接的例子，其中使用`贝叶斯网络`来描述用户、项目和评分之间的条件依赖关系。具体地说，`PMF` 假定了以下生成过程：

(1) 对每一个项目 $j$， 抽取隐项目向量： $\mathbf{v}_{i} \sim \mathcal{N}\left(\mathbf{0}, \lambda_{v}^{-1} \mathbf{I}_{K}\right)$.

(2) 对于每个用户 $i$ ，抽取隐用户向量： $\mathbf{u}_{i} \sim \mathcal{N}\left(\mathbf{0}, \lambda_{u}^{-1} \mathbf{I}_{K}\right)$.

(3) 对于每个（用户-项目）对 $(i, j)$，抽取评分： $\mathbf{R}_{i j} \sim \mathcal{N}\left(\mathbf{u}_{i}^{T} \mathbf{v}_{j}, \mathbf{C}_{i j}^{-1}\right.$ ).

在上述生成过程中，$\mathrm{C}_{i j}^{-1}$ 对应于评分的方差 $\mathrm{R}_{i j}$。 通过使用最大后验估计，学习 PMF 的数量，以最大化 $p\left(\left\{\mathbf{u}_{i}\right\},\left\{\mathbf{v}_{j}\right\} \mid\left\{\mathbf{R}_{i j}\right\},\left\{\mathbf{C}_{i j}\right\}, \lambda_{u}, \lambda_{v}\right)$ 的 log 似然：

$$
\mathscr{L}=-\frac{\lambda_{u}}{2} \sum_{i}\left\|\mathbf{u}_{i}\right\|_{2}^{2}-\frac{\lambda_{v}}{2} \sum_{j}\left\|\mathbf{v}_{j}\right\|_{2}^{2}-\sum_{i, j} \frac{\mathrm{C}_{i j}}{2}\left(\mathbf{R}_{i j}-\mathbf{u}_{i}^{T} \mathbf{v}_{j}\right)^{2} \notag
$$

请注意，还可以通过完全贝叶斯处理将另一层先验强加给超参数。例如，`[97]` 对潜在因子的精度矩阵施加先验，并通过 `Gibbs 抽样`学习`贝叶斯 PMF`。

在 `5.1 节`中，我们将展示如何将 `PMF` 用作任务组件，以及定义用于显著提高推荐系统性能的感知组件。

#### （2）双向推断网络（Bidirectional Inference Networks，BIN）

典型`贝叶斯网络`假定随机变量之间存在“浅”的条件依赖关系。在生成过程中，通常从由其母变量的线性组合参数化的条件分布中提取一个随机变量（可以是隐变量，也可以是可观测变量）。例如，在 `PMF` 中，从主要由 $u_i$ 和 $v_j$ 的线性组合参数化的高斯分布中提取评级 $R_{i j}$ ，即 $R_{i j}∼\mathcal{N}(u^T_iv_j，C^{−1}_{i j})$。

这种“浅”的线性结构可以用非线性甚至深的非线性结构来代替，从而形成一个深的`贝叶斯网络`。例如，`双向推断网络 (BIN)[117]` 是一类`深度贝叶斯网络`，其在每个条件分布中启用深度非线性结构，同时保留将先验知识合成为`贝叶斯网络`的能力。

例如，`图 6（左）` 显示了 `BIN`，其中每个条件分布由贝叶斯神经网络参数化。具体地说，此示例假定进行以下因子分解：

$$
p\left(v_{1}, v_{2}, v_{3} \mid X\right)=p\left(v_{1} \mid X\right) p\left(v_{2} \mid X, v_{1}\right) p\left(v_{3} \mid X, v_{1}, v_{2}\right) \notag
$$

普通`贝叶斯网络`通过简单的线性运算对每个分布进行参数化。例如，$p(v2|X，v_1)=N(v_2|Xw_0+v_1w_1+b，σ^2)$ 。相反，BIN 使用 `BNN` 。例如，BIN 有 $p(v_2|X，v_1)=\mathcal{N}(v_2|µ_\theta(X，v_1)，s_\theta(X，v_1))$ ，其中 $\mu_\theta(X，v_1)$ 和 $s_\theta(X，v_1)$ 是 `BNN` 的输出均值和方差。通过对所有 `BNN` （例如，图 6（左）中的 `BNN` 1、 `BNN` 2 和 `BNN` 3) 执行返向传播来完成对`深层贝叶斯网络`的推断和学习 `[117]`。

![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/bayesian_stat_2021051915021738.webp)

图 6 左：BIN 的一个简单示例，每个条件分布由贝叶斯神经网络或简单地用概率神经网络参数化。右：另一个 BIN 案例。阴影节点和透明节点分别表示可观测变量和隐变量。

与普通贝叶斯网络相比，`深度贝叶斯网络`（如 BIN） 可以有效、高效地处理深度和非线性的条件依赖。此外，基于`深度贝叶斯网络`的任务组件以神经网络为构建块，可以更好地与感知组件协同工作，感知组件通常也是一个神经网络。`图 6（右）`显示了一个更复杂的情况，其中既有可观测变量（阴影节点），也有不可观测变量（透明节点）。

#### （3）随机过程（Stochastic Processes，SP）

除了`普通贝叶斯网络`和`深度贝叶斯网络`之外，任务组件也可以采取`随机过程`的形式 `[94]` 。例如，`维纳过程`可描述连续时间的布朗运动模型 $x_{t+u}|x_t∼N(x_t，λ_uI)$，其中 $x_{t+u}$和 $x_t$ 分别是时间 $t$ 和 $t+u$ 的状态。在概率图模型文献中，此过程已被用来对博客主题随连续时间的演变过程进行建模`[113]`。

另一个例子是在自动语音识别任务中使用`泊松过程`对音素边界位置进行建模`[51]`。具体地说，`泊松过程`定义了生成过程 $∆t_i=t_i−t_{i−1}∼g(λ(t))$ ，其中$t={t_1，t_2，.。，t_N}$ 作为边界位置集合，$g(λ(t))$ 是参数为 $λ(t)$ （也称为强度）的指数分布。该随机过程自然地模拟了连续时间内音素边界的出现。参数 $λ(t)$ 可以是将原始语音信号作为输入的神经网络的输出 `[51，83，99]`。

有趣的是，`随机过程可以看作是一种动态贝叶斯网络`。为理解这一点，可以用等价形式重写上面的泊松过程，其中给定 $t_{i−1}$ ，在时间 $t$ 没有发生 $t_i$ 的概率 $P(t_i>t)=exp(∫_{t_{i−1}}^{t_i}−λ(t)dt)$ 。显然，维纳过程和泊松过程都是马尔可夫过程，可以用动态贝叶斯网络来表示 `[78]`。

为方便讲解，`第 5 节` 重点使用`普通贝叶斯网络`作为任务组件；它们可以自然地替换为其他类型的任务组件，以表示不同的先验知识。

## 6.5 具体的贝叶斯深度学习模型和应用

在本节中，我们讨论 `贝叶斯深度学习框架` 如何促进监督学习、非监督学习和表示学习。具体结合推荐系统、主题模型、控制系统等领域实例展开。
### 6.5.1 推荐系统中的有监督贝叶斯深度学习


```{note}
推荐系统可被定义为一种程序，通过对某项项目的信息、用户、项目与用户间的交互来预测用户感兴趣的内容，从而向特定用户推荐最适合的产品或服务。其主要目标是从海量信息中选出相关信息从而解决信息过载问题。推荐系统最重要的功能是通过分析特定用户与其他用户的行为来“猜测”用户的偏好和兴趣，生成个性化推荐。
目前主流推荐算法包括：

（1）基于内容的推荐算法

    通过分析新产品（属性或特征）与用户已购或感兴趣产品（属性或特征）之间的相似度，进而为用户推荐新产品。例如：用户喜欢 `Java开发`的书籍，则基于内容的推荐算法将用户尚未看过的其他 `Java 开发` 方面的书籍推荐给用户。该算法通常包括：产品特征提取、用户特征学习、新产品特征相似度计算与推荐等环节，而计算相似度的常见方法有皮尔逊相关系数法、夹角余弦法、Jaccard相关系数法等。

（2）基于协同过滤的推荐算法

    通过分析用户与产品之间的联系，来寻找用户与其他产品之间新的相关性，进而为用户推荐产品。相关算法又可大致分为三类：
    - 基于用户的协同过滤（User-Based Collaborative Filtering,UBCF）
    例如：用户 A 和用户 B 相似，则可以将用户 B 喜欢而用户 A 尚未关注的产品推荐给用户 A。

    - 基于项目的协同过滤（Item-Based Collaborative Filtering, IBCF）
    例如：某用户喜欢产品 M，则其喜欢与产品 M 高度相似且还未被用户关注的项目 N 的可能性非常大，因此将项目 N 推荐给用户。

    - 基于模型的协同过滤（Model-Based Collaborative Filtering, MBCF）
    基于用户和基于项目的协同过滤均是在线计算模型，需要基于全局数据进行计算，但随着用户和项目数量的变化，系统性能会严重下滑。因此研究人员提出了离线建模和在线过滤结合的推荐算法。其基本思路是通过矩阵奇异值分解、聚类等方法对用户的历史数据进行离线的建模，而后基于离线模型对在线数据进行推荐。

（3）混合推荐算法

    通过混合不同推荐算法的中间结果或最终结果，生成新推荐。例如：多算法的推荐结果混合加权、不同相似度的混合加权等。
```

尽管深度学习在自然语言处理和计算机视觉领域得到了成功应用，但在贝叶斯深度学习出现前，很少有人尝试开发用于协同过滤的深度学习推荐算法。[98] 使用 `受限 Boltzmann 机器` 而不是传统矩阵分解公式来执行协同过滤；[28] 通过集成 `用户-用户`、`项目-项目` 相关性做了进一步扩展。虽然这些方法同时涉及深度学习和内容过滤，但其本质上还是属于深度学习方法，因为它们其实忽略了用户或项目的内容信息，而这对于准确推荐至关重要。[95] 在深层网络的最后权重层使用低秩矩阵因子分解，可显著减少模型参数数量、加快训练速度，但它仅用于分类任务。在音乐推荐方面，[84,123] 直接使用传统的 `CNN` 或`深度信念网络 (DBN)`来辅助内容信息的表示学习，但其模型的深度学习部分是确定性的，没有对噪声建模，稳健性较差。上述模型通过松散耦合方式实现性能提升，但没有利用内容信息和评分之间的交互。此外， `CNN` 方法直接与评级矩阵联系在一起，当评级数据稀疏时，存在严重的过拟合问题。

#### 6.5.1.1 什么是协同深度学习（Collaborative Deep Learning）？

为了解决上述问题，文献 [121] 提出了一种称为`协同深度学习 (CDL)` 的层次化贝叶斯模型，作为一种紧耦合推荐方法。基于`堆叠去噪自编码器 (SDAE)`的贝叶斯公式， `协同深度学习`实现了`内容信息深度表示学习`与`评级矩阵协同过滤`之间的紧耦合，允许两者之间双向交互。从贝叶斯深度学习角度来看，作为感知组件的 `pSDAE` 与作为任务组件的`PGM`紧密耦合。实验表明， `协同深度学习`在现有技术基础上有了很大的提高。

在下面的文本中，我们将从介绍 `协同深度学习`时使用的符号开始。之后，将回顾 `协同深度学习`的设计和学习。

##### （1）记法和问题表述

与 [112] 中的工作类似， `协同深度学习`中考虑的推荐任务将隐式反馈 [50] 作为训练和测试数据。拥有 $J$ 个项目的完整数据集由 $J \times B$ 矩阵 $X_c$ 表示，其中行 $j$ 是大小为 $B$ 的词汇表中，第 $j$ 个词的词袋向量 $X_{c,j∗}$。对于 $I$ 个用户，我们定义 $I \times J$ 的二值评级矩阵 $R=[R_{ij}]_{I \times J}$ 。例如，在 `Citeulike-a 数据集  [112,115,121]`中，如果用户 $i$ 在个人库中有文章 $j$，则 $R_{ij}=1$，否则 $R_{ij}=0$ 。在给定 $R$ 中的部分评级数据和内容信息 $X_c$ 情况下，问题是：`请预测出 $R$ 中的其他评级`。 尽管`协同深度学习`在其当前案例中侧重于电影和文章推荐 [112]，但也可用于处理其他推荐任务（如标签推荐）。

矩阵 $X_c$ 起到`堆叠去噪自编码器 (SDAE)`中干净输入的作用，而被噪声破坏的矩阵（也是一个 $J \times B$ 矩阵）由 $X_0$ 表示。`堆叠去噪自编码器 (SDAE)`的第 $l$ 层输出由 $X_l$ 表示，$X_l$ 是一个 $J \times K_l$ 矩阵。与 $X_c$ 类似，$X_l$ 的第 $j$ 行由 $X_{l,j∗}$ 表示。$W_l$ 和 $b_l$ 分别表示层 $l$ 的权重矩阵和偏置向量，$W_{l,∗n}$ 表示 $W_l$ 的第 $n$ 列，$L$ 表示总层数。为方便起见，使用 $W^+$ 表示所有层权重矩阵和偏置的集合。注意，一个 $L/2$ 层`堆叠去噪自编码器 (SDAE)`对应于一个 $L$ 层的神经网络。

##### （2）协同深度学习

使用 `6.4.3.2 节`提到的 `pSDAE` ， `协同深度学习模型`的生成过程如下：

![图片](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210623163452_a7.webp)

这里，$λ_w$、$λ_n$、$λ_u$、$λ_s$ 和 $λ_v$ 是超参数，$C_{ij}$ 是类似于 `CTR [112]` 的置信度参数（如果 $R_[ij]=1$，则 $C_{ij}=a$ ，否则 $C_{ij}=b$ ）。注意，中间层 $X_{L/2}$ 充当评级数据和内容信息之间的桥梁。该中间层以及潜在偏移量 $ϵ_j$ 是使 `协同深度学习`能够同时学习有效特征表示并捕捉项目（和用户）之间相似性和关系的关键。与 `广义 SDAE` 类似，为提高计算效率，也可以把 $λ$ 取为无穷大。

当 $λ_s$ 接近正无穷大时， `协同深度学习`的概率图模型如 `图 7` 所示，其中，为表示简单起见，分别使用 $\mathbf{x}_0$，$\mathbf{x}_{L/2}$ 和 $\mathbf{x}_L$ 来代替 $\mathbf{X}_{0,j∗}^T$，$\mathbf{X}_{2/L,j∗}^T$ 和 $\mathbf{X}_{L,j∗}^T$ 。

注意，根据 `第 6.4.2 节`中的定义，这里感知变量 $\Omega_p=\{ \{W_l\}，\{b_l\}，\{X_l\}，X_c \}$，铰链变量 $\Omega_h=\{V\}$，以及任务变量 $\Omega_t=\{U，R\}$。

![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210528091403_5b.webp)

图 7. 左边是 `协同深度学习`的概率图模型。虚线矩形内的组件表示`堆叠去噪自编码器 (SDAE)`。给出了一个 $L=2$ 的`堆叠去噪自编码器 (SDAE)`实例。右边是退化的 `协同深度学习`概率图模型。虚线矩形内的部分表示`堆叠去噪自编码器 (SDAE)`的编码器。右侧显示了 $L=2$ 的`堆叠去噪自编码器 (SDAE)`示例。注意，虽然 $L$ 仍然是 2，但`堆叠去噪自编码器 (SDAE)`的解码器消失了。为了避免混乱，我们省略了概率图模型中除 $\mathbf{x}_0$ 和 $\mathbf{x}_{L/2}$ 之外的所有变量 $\mathbf{x}_l$。

##### （3）学习

基于上述 `协同深度学习`模型，所有参数都可以看作随机变量，从而可以应用马尔可夫链蒙特卡罗 ( `MCMC` ) 或 `变分推断` 等完全贝叶斯方法 [55]。然而，这样的处理通常会导致很高的计算成本。因此， `协同深度学习`使用 `EM 风格`的算法来获得 `MAP` 估计，如 [112] 中所示。

具体地说，在给定 $λ_u$、$λ_v$、$λ_w$、$λ_s$ 和 $λ_n$ 的情况下，最大化后验概率等同于最大化 $U$、$V$、$\{\mathbf{X}_l\}$、$\mathbf{X}_c$、$\{W_l\}$、$\{ b_l\}$ 和 $\mathbf{R}$ 的联合对数似然：

$$
\begin{aligned} \mathscr{L}=&-\frac{\lambda_{u}}{2} \sum_{i}\left\|\mathbf{u}_{i}\right\|_{2}^{2}-\frac{\lambda_{w}}{2} \sum_{l}\left(\left\|\mathbf{W}_{l}\right\|_{F}^{2}+\left\|\mathbf{b}_{l}\right\|_{2}^{2}\right)-\frac{\lambda_{v}}{2} \sum_{j}\left\|\mathbf{v}_{j}-\mathbf{X}_{\frac{L}{2}, j *}^{T}\right\|_{2}^{2}-\frac{\lambda_{n}}{2} \sum_{j}\left\|\mathbf{X}_{L, j *}-\mathbf{X}_{c, j *}\right\|_{2}^{2} \\ 
&-\frac{\lambda_{s}}{2} \sum_{l} \sum_{j}\left\|\sigma\left(\mathrm{X}_{l-1, j *} \mathrm{~W}_{l}+\mathbf{b}_{l}\right)-\mathbf{X}_{l, j *}\right\|_{2}^{2}-\sum_{i, j} \frac{\mathrm{C}_{i j}}{2}\left(\mathrm{R}_{i j}-\mathbf{u}_{i}^{T} \mathbf{v}_{j}\right)^{2} \end{aligned}
$$

注意，当 $\lambda_s$ 趋向无穷时，似然转变为：

$$
\begin{aligned} \mathscr{L}=&-\frac{\lambda_{u}}{2} \sum_{i}\left\|\mathbf{u}_{i}\right\|_{2}^{2}-\frac{\lambda_{w}}{2} \sum_{l}\left(\left\|\mathbf{W}_{l}\right\|_{F}^{2}+\left\|\mathbf{b}_{l}\right\|_{2}^{2}\right)-\frac{\lambda_{v}}{2} \sum_{j}\left\|\mathbf{v}_{j}-f_{e}\left(\mathbf{X}_{0, j *}, \mathbf{W}^{+}\right)^{T}\right\|_{2}^{2} \\ 
&-\frac{\lambda_{n}}{2} \sum_{j}\left\|f_{r}\left(\mathbf{X}_{0, j *}, \mathbf{W}^{+}\right)-\mathbf{X}_{c, j *}\right\|_{2}^{2}-\sum_{i, j} \frac{\mathbf{C}_{i j}}{2}\left(\mathbf{R}_{i j}-\mathbf{u}_{i}^{T} \mathbf{v}_{j}\right)^{2} \end{aligned}
$$

其中，编码器函数 $f_e(·,W^+)$ 将项 $j$ 的损坏内容向量 $\mathbf{X}_{0,j∗}$ 作为输入并计算其编码，而函数 $f_r(·,W^+)$ 也以 $\mathbf{X}_{0,j∗}$ 作为输入，计算编码，然后重建项目 $j$ 的内容向量。例如，如果层数 $L=6$， $f_e(\mathbf{X}_{0,j*},W^+)$ 是第三层的输出，而 $f_r(\mathbf{X}_{0,j*},W^+)$ 是第六层的输出。

从优化的角度看，上面目标函数中的第三项，即等式 (9)，相当于使用潜在项目向量 $V_j$ 作为目标的多层感知机，而第四项相当于使重建误差最小的`堆叠去噪自编码器 (SDAE)`。从神经网络的观点来看，当 $λ$ 接近正无穷大时，`图 7（左）`中的 `协同深度学习`概率图模型的训练将退化为同时训练两个叠加在一起的神经网络，该两个神经网络具有共同的输入层（被破坏的输入）和不同的输出层，如`图 8（左）`所示。请注意，由于评级矩阵的参与，第二个网络比典型神经网络要复杂得多。

当 $λ_n/λ_v$ 的比值趋于正无穷大时，它将退化为一个两步模型，在该模型中，使用`堆叠去噪自编码器 (SDAE)`学习的潜在表征被直接放入 `CTR`。另一个极端发生在 $λ_n/λ$ 为零时，其中 `SDAE` 的解码器基本消失。`图 7（右）`显示了当 $λ_n/λ$ 为零时退化的 `协同深度学习`概率图模型。正如实验证明的那样，对于这两种极端情况，预测性能都会受到很大影响 [121]。

![](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210528092323_74.webp)

图 8. 左：退化协同深度学习的神经网络表示。右图：贝叶斯协同深度学习中的广义返向传播抽样。

对于 $u_i$ 和 $v_j$，使用类似于 [50,112] 的区块坐标下降。给定当前的 $W^+$ ，计算 $\mathscr{L}$ 相对于 $u_i$ 和 $v_j$ 的梯度，然后将其置为零，从而产生以下更新规则：

$$
\mathbf{u}_{i} \leftarrow\left(\mathbf{V C}_{i} \mathbf{V}^{T}+\lambda_{u} \mathbf{I}_{K}\right)^{-1} \mathbf{V C}_{i} \mathbf{R}_{i}, \quad \mathbf{v}_{j} \leftarrow\left(\mathbf{U C}_{i} \mathbf{U}^{T}+\lambda_{v} \mathbf{I}_{K}\right)^{-1}\left(\mathbf{U C}_{j} \mathbf{R}_{j}+\lambda_{v} f_{e}\left(\mathbf{X}_{0, j *}, \mathbf{W}^{+}\right)^{T}\right)
$$

式中 $U=(u_i)_{i=1}^I$ ，$V=(v_j)^J_{j=1}$ ，$C_i=diag(C_{i1},...,C_{iJ})$ 是对角矩阵，$R_i=(R_{i1},...,R_{iJ})^T$ 是包含用户 $i$ 所有评级的列向量，并且 $C_{i_j}$ 反映了由 $a$ 和 $b$ 控制的信念（如在 [50] 中所讨论的）。对于项目 $j$，类似地定义 $C_j$ 和 $R_j$。

在给定 U 和 V 的情况下，我们可以使用返向传播学习算法来学习每一层的权重 Wland 偏差 BLE。关于 Wland BLAND 的可能性梯度如下：
$$
\begin{align*}
\nabla_{\mathbf{W}_{l}} \mathscr{L}=&-\lambda_{w} \mathbf{W}_{l}-\lambda_{v} \sum_{j} \nabla_{\mathbf{W}_{l}} f_{e}\left(\mathbf{X}_{0, j^{*}}, \mathbf{W}^{+}\right)^{T}\left(f_{e}\left(\mathbf{X}_{0, j *}, \mathbf{W}^{+}\right)^{T}-\mathbf{v}_{j}\right) \\ 
&-\lambda_{n} \sum_{j} \nabla_{\mathbf{W}_{l}} f_{r}\left(\mathbf{X}_{0, j *}, \mathbf{W}^{+}\right)\left(f_{r}\left(\mathbf{X}_{0, j *}, \mathbf{W}^{+}\right)-\mathbf{X}_{c, j *}\right) \\
\nabla_{\mathbf{b}_{l}} \mathscr{L}=&-\lambda_{w} \mathbf{b}_{l}-\lambda_{v} \sum_{j} \nabla_{\mathbf{b}_{l}} f_{e}\left(\mathbf{X}_{0, j *}, \mathbf{W}^{+}\right)^{T}\left(f_{e}\left(\mathbf{X}_{0, j *}, \mathbf{W}^{+}\right)^{T}-\mathbf{v}_{j}\right) \\
&-\lambda_{n} \sum_{j} \nabla_{\mathbf{b}_{1}} f_{r}\left(\mathbf{X}_{0, j *}, \mathbf{W}^{+}\right)\left(f_{r}\left(\mathbf{X}_{0, j *}, \mathbf{W}^{+}\right)-\mathbf{X}_{c, j *}\right) 
\end{align*}
$$
通过交替更新 U、V、WL 和 BL，我们可以找到 L 的局部最优解。几种常用的技术，例如使用动量项，可以用来缓解局部最优解问题。

##### （4）预测

设 D 为观测试验数据。与 [112] 类似， `协同深度学习`使用 UI、W+和ϵJTTO 的点数估计来计算预测评级
$$
E\left[\mathbf{R}_{i j} \mid D\right] \approx E\left[\mathbf{u}_{i} \mid D\right]^{T}\left(E\left[f_{e}\left(\mathbf{X}_{0, j *}, \mathbf{W}^{+}\right)^{T} \mid D\right]+E\left[\epsilon_{j} \mid D\right]\right)
$$
其中 E[·] 表示期望运算。换句话说，我们将预测的评级近似为：
$$
\mathbf{R}_{i j}^{*} \approx\left(\mathbf{u}_{j}^{*}\right)^{T}\left(f_{e}\left(\mathbf{X}_{0, j *}, \mathbf{W}^{+*}\right)^{T}+\boldsymbol{\epsilon}_{j}^{*}\right)=\left(\mathbf{u}_{i}^{*}\right)^{T} \mathbf{v}_{j}^{*}
$$
注意，对于训练数据中没有评级的任何新项目 j，其偏移量ϵ∗j 将为 0。

回想一下，在 `协同深度学习`中，概率`堆叠去噪自编码器 (SDAE)`和 PMF 作为感知和特定于任务的组件工作。如第 4 节所述，这两个组件可以采用不同的形式，从而产生不同的具体模型。例如，可以将概率`堆叠去噪自编码器 (SDAE)`替换为 V `AE` 或 NPN 作为感知分量 [68]。还可以使用贝叶斯 PMF[97] 而不是 PMF[96] 作为特定于任务的组件，从而产生更稳健的预测。

在接下来的小节中，我们将从不同的角度提供 `协同深度学习`的几个扩展。

#### 6.5.1.2 贝叶斯协作式深度学习

除了 `MAP` 估计外，文献 [121] 中还提出了一种基于抽样的 `协同深度学习`贝叶斯处理算法。事实证明，该算法是 BP 的贝叶斯和广义版本。我们将关键的条件密度列出如下：

![图片](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210528093005_72.webp)

有趣的是，如果λ趋于无穷大，并且使用自适应拒绝 Metropolis 抽样（涉及使用目标函数的梯度来近似建议分布），则 W+的抽样被证明是 BP 的贝叶斯广义版本。具体地说，如图 8（右）所示，在获得损失函数在一点（左侧的红色虚线）的梯度后，将在该线下的区域中绘制下一个样本，这相当于 BP 的概率版本。如果样本在损失函数的曲线之上，则会添加一条新的切线（右侧的黑色虚线），以更好地近似与损失函数对应的分布。之后，将从这两条线下的区域抽取样本。在采样过程中，该算法除了使用梯度 ( `MAP` ) 搜索局部最优值外，还考虑了方差。这就是 [121] 中称之为贝叶斯广义返向传播的原因。

#### 6.5.1.3 边缘化`协同深度学习`（Marginalized Collaborative Deep Learning）

在`堆叠去噪自编码器 (SDAE)`中，损坏的输入通过编码器和解码器恢复干净的输入。通常，不同的训练阶段使用不同的损坏版本作为输入。因此，通常情况下，`堆叠去噪自编码器 (SDAE)`需要经历足够多的培训阶段，才能看到足够多的输入损坏版本。边缘化的`堆叠去噪自编码器 (SDAE)`(M`堆叠去噪自编码器 (SDAE)`)[14] 试图通过将被破坏的输入边缘化并直接获得封闭形式的解决方案来避免这种情况。从这个意义上说，m`堆叠去噪自编码器 (SDAE)`比`堆叠去噪自编码器 (SDAE)`的计算效率更高。

正如在 [66] 中提到的，使用 m`堆叠去噪自编码器 (SDAE)`而不是贝叶斯`堆叠去噪自编码器 (SDAE)`可能会导致更有效的学习算法。例如，在 [66] 中，使用单层 m`堆叠去噪自编码器 (SDAE)`时的目标可以写成：
$$
\mathscr{L}=-\sum_{i}\left\|\tilde{\mathbf{X}}_{0, j *} \mathbf{W}_{1}-\overline{\mathbf{X}}_{c, j *}\right\|_{2}^{2}-\sum_{i, i} \frac{\mathbf{C}_{i j}}{2}\left(\mathbf{R}_{i j}-\mathbf{u}_{i}^{T} \mathbf{v}_{j}\right)^{2}-\frac{\lambda_{u}}{2} \sum_{i}\left\|\mathbf{u}_{i}\right\|_{2}^{2}-\frac{\lambda_{v}}{2} \sum_{i}\left\|\mathbf{v}_{j}^{T} \mathbf{P}_{1}-\mathbf{X}_{0, j *} \mathbf{W}_{1}\right\|_{2}^{2}
$$
其中 X0，j∗是 k 个不同损坏版本的 X0，j∗(AK 乘 B 矩阵）和 XC 的集合，j∗是 XC，j∗（也是 k 乘 B 矩阵）的 k 次重复版本。P1 是项目潜在因素的转换矩阵。

W1 的解将是 W1=E(S1)E(Q1)−1，其中 s1=xtc，j∗ex0，j∗+λv 2pt 1Vxc 和 q1=xt c，j∗ex0，j∗+λv 2xt cxc。上述方程中的期望值的求解器在 [14] 中提供。请注意，这是一个线性和单层情况，可以使用与 [13，14] 中相同的技术将其推广到非线性和多层情况。边缘化 `协同深度学习`的感知变量Ωp={X0，Xc，W1}，铰链变量Ωh={V}，任务变量Ωt={P1，R，U}。

#### 6.5.1.4 协作深度排名（Collaborative Deep Ranking）

 `协同深度学习`采用协作过滤设置来直接对评级进行建模。当然，人们可以设计一个类似的模型，更多地关注项目之间的排名，而不是确切的评级 [131]。相应的生成过程如下：

![图片](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210528093316_19.webp)

在上述生成过程之后，公式 (9) 中的对数似然变为：

![图片](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210528093320_8a.webp)

类似的算法可以用来学习 CDR 中的参数。如 [131] 所述，使用排名目标可以显著提高推荐性能。根据第 4.2 节中的定义，CDR 的感知变量Ωp={{wl}，{bl}，{xl}，xc}，铰链变量Ωh={V}，以及任务变量Ωt={U，∆}。

#### 6.5.1.5 协作式变分自编码器（Collaborative Variational Autoencoders）

在 `协同深度学习`中，感知组件采用概率`堆叠去噪自编码器 (SDAE)`的形式。当然，也可以用 V AE（在第 4.3.3 节中介绍）替换 `协同深度学习`中的概率`堆叠去噪自编码器 (SDAE)`，就像在协作变分自编码器 (CV AE)[68] 中所做的那样。具体地说，具有表示为 (fµ(·)，fs(·)) 的推理网络（编码器）和表示为д(·) 的生成网络（解码器）的 CV `AE` 采取以下生成过程：

![图片](https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfp0G9xjCH5OudvPdPBngyxtNSI0tFjUxFUtOvbyMX7eE4lzmpt5uibwBbfjsTwJ7QtS2bFGz0tMrKw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

类似于 cdl，λn、λu、λs 和λV1 是超参数，Ci j 是置信度参数（如果 Ri j=1，则 Ci j=a，否则 Ci j=b)。在 [68] 之后，可以导出类似于公式 (6) 的 ELBO，使用它可以使用 BP 和重新参数化技巧来训练模型的参数。

从 `协同深度学习`到 CV `AE` 的演变展示了 `贝叶斯深度学习` 框架在组件特定形式方面的灵活性。还值得注意的是，感知组件可以是概率`堆叠去噪自编码器 (SDAE)`[122] 或 VAE[17，68] 的递归版本以处理原始顺序数据，而特定于任务的组件可以采取更复杂的形式以适应更复杂的推荐场景（例如，跨域推荐）。

#### 6.5.1.6 讨论

推荐系统是 `贝叶斯深度学习` 的典型用例，因为它们通常既需要彻底理解高维信号（例如，文本和图像），又需要对用户/项目/评级之间的条件依赖关系进行原则性推理。

在这一点上， `协同深度学习`作为 `贝叶斯深度学习` 的实例化，是第一个弥合现有深度学习模型和推荐系统之间差距的分层贝叶斯模型。通过协作进行深度学习， `协同深度学习`及其变体可以同时从高维内容中提取有效的深层特征表示，并捕捉项目（和用户）之间的相似性和隐含关系。学习的表示还可以用于除推荐之外的任务。与以前的深度学习模型使用简单的目标（如分类 [56] 和重构 [111]) 不同，基于 `协同深度学习`的模型在概率框架中使用 CF 作为更复杂的目标。

如第 1 节所述，两个组件之间的信息交换对 `贝叶斯深度学习` 的性能至关重要。在上述基于认知学习的模型中，通过假设连接铰链变量和感知成分中的变量的高斯分布来实现交换（在认知学习的生成过程中绘制铰链变量 Vj∼N(Xt L2，j∗，λ−1 Vik)，其中 XL2 是感知变量），这在计算上是简单而有效的。根据 4.2 节的定义，在表 1 中的 8 个基于 `协同深度学习`的模型中，其中 6 个是 HV 模型，其余是 LV 模型。由于已经证实 HV `协同深度学习`的性能明显优于 ZV 对应车型 [121]，我们可以预期 6 款 HV 车型的 LV 对应车型会带来额外的性能提升。

除了有效的信息交换，模型设计还满足 4.2 节中讨论的铰链变量分布的独立性要求，因此易于并行化。在稍后将介绍的一些模型中，我们将看到支持 `贝叶斯深度学习` 的两个组件之间高效且独立的信息交换的替代设计。

请注意，上述基于 `贝叶斯深度学习` 的模型使用典型的静态贝叶斯网络作为其特定于任务的组件。虽然这些对于大多数用例来说通常是足够的，但是特定于任务的组件也可以采用深度贝叶斯网络的形式，例如 BIN[117]。这允许模型在必要时处理用户和项目之间的高度非线性交互。人们还可以使用随机过程（或者一般的动态贝叶斯网络）来明确地对用户购买或点击行为进行建模。例如，将用户购买食品杂货的过程建模为泊松过程是很自然的。就感知分量而言，还可以用它们的卷积或递归对应物替换上面的 p`堆叠去噪自编码器 (SDAE)`、m`堆叠去噪自编码器 (SDAE)`或 V AE（参见第 6.2.3 节和第 6.2.4 节），如分别在协作知识库嵌入 (CKE)[132] 或协作递归自编码器 (CRAE)[122] 中所做的那样。注意，为了使卷积或递归感知分量与特定于任务的分量（其本质上是概率的）兼容，理想情况下，还需要制定 `CNN` 或 `RNN` 的概率版本。读者可参考 [132] 和 [122] 了解更多详细信息。

总而言之，本小节以推荐系统为例，讨论了 `贝叶斯深度学习` 在有监督的借贷方面的应用。下面的第 5.2 节将介绍 `贝叶斯深度学习` 在无监督学习方面的应用。

### 6.5.2 主题模型中的无监督贝叶斯深度学习

为了演示 `贝叶斯深度学习` 如何也可以应用于无监督学习，我们在本节中回顾了一些基于 `贝叶斯深度学习` 的主题模型的示例。这些模型结合了`概率图模型`（自然地结合了变量之间的概率关系）和 NN（高效地学习深层表示）的优点，导致了显著的性能提升。在无监督学习的情况下，特定于任务的组件的“任务”是描述/表征 `贝叶斯深度学习模型` 中的条件依赖关系，从而提高其可解释性和类型化。这与监督学习设置不同，在监督学习设置中，“任务”只是简单地“匹配目标”。

#### 6.5.2.1 作为主题模型的相关堆叠去噪自编码器（Relational Stacked Denoising Autoencoders as Topic Models）

作为一种基于 `贝叶斯深度学习` 的主题模型，关系堆叠去噪自编码器 (R`堆叠去噪自编码器 (SDAE)`) 本质上试图学习主题的层次结构（或潜在因素），同时在无监督学习环境下实施关系（图）约束。

##### （1）问题陈述

假设我们有一组项（文章或电影）Xc，其中 Xtc，j∗∈Rb 表示项 j 的内容（属性）。此外，我们用 Ik 表示 K 维恒等矩阵，S=[S1，S2，···，Sj] 表示关系潜在矩阵，其中 sj 表示项 j 的关系属性。

从`堆叠去噪自编码器 (SDAE)`的角度来看，J-x-B 矩阵 Xcreen 表示对`堆叠去噪自编码器 (SDAE)`的干净输入，并且相同大小的噪声损坏的矩阵由 X0 表示。此外，我们用 XL 表示`堆叠去噪自编码器 (SDAE)`的层 l 的输出，即 J×Kl 矩阵。XLi 的第 j 行由 XL 表示，j∗，Wland blare 层 l，WL 的权重矩阵和偏置向量，∗n 表示 WL 的第 n 列，L 是层数。作为速记，我们将所有层中的权重矩阵和偏差的集合称为 W+。注意，L/2 层`堆叠去噪自编码器 (SDAE)`对应于 L 层网络。

##### （2）模型构建

在 R`堆叠去噪自编码器 (SDAE)`中，感知组件采用概率`堆叠去噪自编码器 (SDAE)`（在 4.3.2 节中介绍）的形式作为构建块。在更高的层次上，R`堆叠去噪自编码器 (SDAE)`被描述为一种新的概率模型，它无缝地集成了潜在因素的层次结构和可用的关系信息。这样，模型可以同时从内容信息和项目之间的关系中学习特征表示 [118]。R`堆叠去噪自编码器 (SDAE)`的图形模型如图 9 所示，生成过程如下所示：

![图片](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210528094119_77.webp)

图 9.L=4 的 R`堆叠去噪自编码器 (SDAE)`图形模型。为防止混乱，此处省略了λ。

![图片](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210528094148_83.webp)

式 (10) 中的 NK，J(0，IK⊗(λ11a)−1) 是定义在 [33] 中的矩阵-变量正态分布，其中第 j 列是 j 项的关系潜在向量 Sj。注意，公式 (10) 中的 NK，J(0，IK L1a)Sj) 是矩阵-变量正态分布，如 [33] 所定义：
$$
p(\mathrm{~S})=\mathcal{N}_{K, J}\left(0, \mathrm{I}_{K} \otimes\left(\lambda_{l} \mathscr{L}_{a}\right)^{-1}\right)=\frac{\exp \left\{\operatorname{tr}\left[-\frac{\lambda_{l}}{2} \mathrm{~S} \mathscr{L}_{a} \mathrm{~S}^{T}\right]\right\}}{(2 \pi)^{J K / 2}\left|\mathbf{I}_{K}\right|^{J / 2}\left|\lambda_{l} \mathscr{L}_{a}\right|^{-K / 2}}
$$
其中运算符⊗表示两个矩阵 [33] 的 Kronecker 积，TR(·) 表示矩阵的迹，Lais 表示包含关系信息的拉普拉斯矩阵。LA=D−A，其中 D 是对角线矩阵，其对角线元素 Dii=˝Jai，A 是表示具有指示项之间的链接（或关系）的二进制项目的关系信息的邻接矩阵。Aj j‘=1 表示项 j 和项 j’之间存在链接，否则 Aj j‘=0。POG(σ(X L 2−1，j∗wl+bl)，St j，λ−1sik，λ−1Rik) 表示高斯 N(σ(X L 2−1，j∗wl+bl)，λ−1Sik) 和高斯 N(ST j，λ−1Rik) 的乘积，高斯 N 也是高斯 [23]。

根据上面的生成过程，最大化后验概率等同于最大化给定λs、λw、λl、λr 和λn 的{xl}、xc、S、{wl}和{bl}的联合对数似然：

![图片](https://gitee.com/XiShanSnow/imagebed/raw/master/images/articles/spatialPresent_20210528094326_68.webp)

其中 xl，j∗=σ(xl−1，j∗wl+bl)。注意，第一项−λl 2tr(Slast) 对应于公式 (12) 中的矩阵变量分布中的 logp(S)。此外，通过简单的操作，我们得到 tr(Slast)=K˝k=1St k∗Lask∗，其中 Sk∗表示 S 的第 k 行。如我们所见，如果项 j 和项 j‘相关联（即，aj j’=1)，则最大化−λl 2tr(STLas) 等同于使 sj 更接近 Sj‘。

在 R`堆叠去噪自编码器 (SDAE)`中，感知变量 $Ωp={{xl}，xc，{wl}，{bl}}$ ，铰链变量 $Ωh={S}$，以及任务变量$Ωt={A}$ 。

##### (3) 学习与推断

[118] 提供了一种 EM 式的 `MAP` 估计算法。下面我们将回顾一些关键步骤。

对于 E 步，挑战在于关系潜在矩阵 S 的推断。我们首先固定 S 的所有行，除了第 k 行 Sk∗，然后更新 Sk∗。具体地说，我们取 L 相对于 Sk∗的梯度，将其设置为 0，得到以下线性系统：

![图片](https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfp0G9xjCH5OudvPdPBngyxtxeLGqR9rlPMowhDfzq8QDHBJ8zbcaC3VOJPTz86GbR9uib2p9KUacdQ/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

#### 6.5.2.2 基于 Sigmoid 信念网络的深度泊松因子分析（Deep Poisson Factor Analysis with Sigmoid Belief Networks）

支持非负整数的泊松分布被认为是建立计数模型的自然选择。因此，希望将其用作主题模型的构建块，主题模型通常对字数统计感兴趣 [8]。基于这一动机，[136] 提出了一种通过泊松分布进行潜在非负矩阵分解的模型，称为泊松因子分析 (PFA)。

##### （1）泊松因子分析

PFA 假设一个离散的 P 乘 N 矩阵 X，其中包含词汇大小为 P[24,136] 的 N 个文档的字数计数。简而言之，PFA 可以使用等式 X∼Pois(Φ(Θ◦H) 来描述，其中Φ（大小为 P×K，其中 K 是主题的数量）表示因子分析中的因子加载矩阵，第 k 列ϕk 编码主题 k 中的每个词的重要性。K×N 矩阵Θ是因子得分矩阵，第 n 列θn 包含文档 n 的主题比例。K×N 矩阵 H 是具有第 n 列 hn 定义的潜在二进制矩阵。

不同的先验对应不同的模型。例如，具有全一矩阵 H 的ϕk 和θn 上的 Dirichlet 先验将恢复 Lda[8]，而 Hn 上的β-Bernoulli 先验将导致 [135] 中的 NB-FTM 模型。在 [24] 中，将基于 `Sigmoid Believe Networks(SBN)（一种二进制隐含单元的 `MLP` 变体）` [79] 的深层先验施加到 HN 上，形成用于主题建模的深层 PFA 模型。

##### （2）深泊松因子分析

在深度 PFA 模型 [24] 中，生成过程可以概括如下：
$$
\phi_{k} \sim \operatorname{Dir}\left(a_{\phi}, \ldots, a_{\phi}\right), \quad \theta_{k n} \sim \operatorname{Gamma}\left(r_{k}, \frac{p_{n}}{1-p_{n}}\right), \quad r_{k} \sim \operatorname{Gamma}\left(\gamma_{0}, \frac{1}{c_{0}}\right), \quad \gamma_{0} \sim \operatorname{Gamma}\left(e_{0}, \frac{1}{f_{0}}\right) 
$$

$$
h_{k_{L} n}^{(L)} \sim \operatorname{Ber}\left(\sigma\left(b_{k_{L}}^{(L)}\right)\right), \quad h_{k_{l} n}^{(l)} \sim \operatorname{Ber}\left(\sigma\left(\mathbf{w}_{k_{l}}^{(l)^{T}} \mathbf{h}_{n}^{(l+1)}+b_{k_{l}}^{(l)}\right)\right), \quad x_{p n k} \sim \operatorname{Pois}\left(\phi_{p k} \theta_{k n} h_{k n}^{(1)}\right), \quad x_{p n}=\sum_{k=1}^{K} x_{p n k}
$$

其中 L 是 SBN 中的层数，其对应于公式 (15)。Xpnk 是来自文档 n 中的主题 k 的单词计数。

在该模型中，感知变量 $Ωp={{H(L)}，{wl}，{bl}}$ ，铰链变量 $Ωh={X}$ ，任务变量 $Ωt={{ϕk}， {rk} ，Θ ，γ0}$ 。W1 是包含 w(L)kland 列的权重矩阵，blis 是包含 B(L)klin 方程 (15) 的项目的偏差向量。

##### （3）使用贝叶斯条件密度滤波进行学习

深度 PFA 的贝叶斯处理需要高效的学习算法。[24] 提出使用贝叶斯条件密度滤波的网络版来学习全局参数Ψд=({ϕk}，{rk}，γ0，{wl}，{bl}) 和局部变量Ψl=(Θ，{H(L)})。用于 Gibbs 更新的关键条件密度如下：
$$
\begin{array}{ll}x_{p n k} \mid-\sim \operatorname{Multi}\left(x_{p n} ; \zeta_{p n 1}, \ldots, \zeta_{p n K}\right), & \phi_{k} \mid-\sim \operatorname{Dir}\left(a_{\phi}+x_{1 \cdot k}, \ldots, a_{\phi}+x_{P \cdot k}\right), \\ \theta_{k n} \mid-\sim \operatorname{Gamma}\left(r_{k} h_{k n}^{(1)}+x_{n k}, p_{n}\right), & h_{k n}^{(1)} \mid-\sim \delta\left(x_{\cdot n k}=0\right) \operatorname{Ber}\left(\frac{\tilde{\pi}_{k n}}{\pi_{k n}+\left(1-\pi_{k n}\right)}\right)+\delta\left(x_{n k}>0\right),\end{array}
$$
where $ \tilde{\pi}_{k n}=\pi_{k n}\left(1-p_{n}\right)^{r_{k}}, \pi_{k n}=\sigma\left(\left(\mathbf{w}_{k}^{(1)}\right)^{T} \mathbf{h}_{n}^{(2)}+c_{k}^{(1)}\right), x_{\cdot n k}=\sum_{p=1}^{P} x_{p n k}, x_{p \cdot k}=\sum_{n=1}^{N} x_{p n k} $, and $ \zeta_{p n k} \propto \phi_{p k} \theta_{k n} . $ For
the learning of $ h_{k_{n}}^{(l)} $ where $ l>1 $, the same techniques as in $ [25] $ can be used.

##### （4）使用随机梯度恒温器进行学习

另一种学习深度 PFA 的方法是通过随机梯度 Nóse-Hoover 恒温器 (SGNHT)，它更精确，更具可扩展性。SGNHT 是随机梯度朗之万动力学 (SGLD)[127] 和随机梯度哈密顿蒙特卡罗 (SGHMC)[15] 的推广。与前两种方法相比，SGNHT 在系统中引入了动量变量，帮助系统跳出局部最优。具体地说，可以使用以下随机微分方程 (SDE)：
$$
d \Psi_{g}=\mathrm{v} d t, \quad d \mathbf{v}=\tilde{f}\left(\Psi_{g}\right) d t-\xi \mathrm{v} d t+\sqrt{D} d \cdot W, \quad d \xi=\left(\frac{1}{M} \mathbf{v}^{T} \mathbf{v}-1\right) d t
$$
其中 EF(Ψд)=−∇ΨдEu(Ψд)) 和 De U(Ψд) 是模型的负对数后验。T 表示时间，W 表示标准维纳过程。ξ是恒温器变量，以确保系统温度恒定。D 是注入方差，它是一个常数。为了加快收敛速度，将 SDE 推广到
$$
d \Psi_{g}=\mathbf{v} d t, \quad d \mathbf{v}=\tilde{f}\left(\Psi_{g}\right) d t-\Xi \mathbf{v} d t+\sqrt{D} d \boldsymbol{W}, \quad d \Xi=(\mathbf{q}-\mathbf{I}) d t
$$
其中 i 是单位矩阵，Ξ=diag(ξ1，.。，ξM)，q=diag(v21，.。，v2M)，M 是参数的维数。

SGNHT、SGLD 和 SGHMC 都属于一大类采样算法，称为混合蒙特卡罗 (HMC)[5]。其想法是利用与物理系统的类比来指导系统状态的转换。与 Metropolis 算法相比，HMC 算法可以在保持较小拒绝概率的情况下对系统状态进行更大的改变。有关更多详细信息，请读者参阅 [5，81]。

#### 6.5.2.3 用受限 Boltzmann 机器进行深泊松因子分析

上面的深度 PFA 模型使用 SBN 作为感知组件。同样，可以使用 RBM `[41]`（在第 4.3.1 节中讨论）替换 SBN，以获得类似的性能。在 RBM 作为感知分量的情况下，公式 (15) 变成类似于公式 (4) 的条件分布，具有如下能量 [41]：

$$
E\left(\mathbf{h}_{n}^{(l)}, \mathbf{h}_{n}^{(l+1)}\right)=-\left(\mathbf{h}_{n}^{(l)}\right)^{T} \mathbf{c}^{(l)}-\left(\mathbf{h}_{n}^{(l)}\right)^{T} \mathbf{W}^{(l)} \mathbf{h}_{n}^{(l+1)}-\left(\mathbf{h}_{n}^{(l+1)}\right)^{T} \mathbf{c}^{(l+1)}
$$

可以使用类似于具有 SBN 的深度 PFA 的学习算法。具体地说，采样过程将在 ${{ϕk}，{γk}，γ0}$和 ${{W(L)}，{c(L)}}$ 之间交替。前者所涉及的条件密度与基于 SBN 的 DPFA 相似。后者是 RBM 的参数，可以使用对比散度算法进行更新。

#### 6.5.2.4 讨论

在这里，我们选择主题模型作为示例应用程序，以演示 `贝叶斯深度学习` 如何应用于无监督学习环境。在基于 `贝叶斯深度学习` 的主题模型中，感知组件负责从文档推断主题层次，而特定于任务的组件负责对词生成、主题生成、词-主题关系或文档间关系进行建模。这两个组成部分之间的协同作用来自于它们之间的双向互动。一方面，关于主题层次的知识有助于准确地建模单词和主题，为学习文档间的关系提供有价值的信息。另一方面，准确地对词语、主题和文档间的关系进行建模，有助于发现文档的主题层次结构，学习文档的紧凑潜在因素。

值得注意的是，一些基于 `贝叶斯深度学习` 的主题模型中的信息交换机制与 5.1 节中的不同。例如，在基于 SBN 的 DPFA 模型中，交换是自然的，因为 SBN 的底层 H(1)，并且 H(1) 和Ωh={X}之间的关系都固有地是概率的，如公式 (15) 所示，这意味着不需要关于分布的额外假设。基于 SBN 的 DPFA 模型相当于假设 PFA 中的 H 是由以 SBN 底层为中心的狄拉克增量分布（具有零方差的高斯分布）H(1) 产生的。因此，根据第 4.2 节中的定义，表 1 中的两个 DPFA 模型都是 ZV 模型。值得注意的是，R`堆叠去噪自编码器 (SDAE)`是一个 HV 模型（参见式 (11)，其中 S 是铰链变量，其他是感知变量），如果天真地将该模型修改为其 ZV 对应物，将违反 I.I.D.。第 4.2 节中的要求。

与 5.1 节类似，上面的基于 `贝叶斯深度学习` 的主题模型使用典型的静态贝叶斯网络作为特定于任务的组件。当然，您可以选择使用其他形式的特定于任务的组件。例如，用随机过程（例如，如 [113] 中的 Wiener 过程）替换 5.2.1 节中 R`堆叠去噪自编码器 (SDAE)`的关系先验是直接的，以对主题层次随时间的演变进行建模。

------------------------------------

![图片](https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfp0G9xjCH5OudvPdPBngyxtTIfbABMaP0vUqFfhV9nH6rXRTMsAokkYn3KUickAhJjKibXVn8JDTPQQ/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

比如说，我们可以通过采用基于 sigmoid belief networks（SBN）的深度先验，构成 DeepPFA 模型。DeepPFA 的生成过程具体如下：

![图片](https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfp0G9xjCH5OudvPdPBngyxtUnmib5pXM2TgGOMLZDNJ88ibibFibuAibf55xnZ4YGvfwEqR2SN4dhAHa6A/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

此模型训练的方式是用 Bayesian Conditional Density Filtering（BCDF），这是 `MCMC` 的一种 online 版本；也可以使用 Stochastic Gradient Thermostats（SGT），属于 hybrid Monto Carlo 类的采样方法。

Deep Poisson Factor Analysis with Restricted Boltzmann Machine：我们也可以将 DeepPFA 中的 SBN 换成 RBM 模型达到相似的效果。

可以看到，在基于 `贝叶斯深度学习` 的话题模型中，感知模块用于推断文本的 topic hierarchy，而任务模块用于对词汇与话题的生产过程，词汇-话题关系，文本内在关系建模。

--------------------------

### 6.5.3 用于控制的贝叶斯深度表示学习

在 5.1 节和 5.2 节中，我们分别介绍了 `贝叶斯深度学习` 如何应用于监督和非监督学习环境中。在本节中，我们将使用控件作为示例应用程序，讨论 `贝叶斯深度学习` 如何在总体上帮助表示学习。

正如第一节所提到的，贝叶斯深度学习也可以应用于从原始图像中控制非线性动力系统。考虑根据从摄像机接收的实时视频流来控制复杂的动态系统。解决这一控制问题的一种方法是通过两个任务之间的迭代，从原始图像中感知和基于动态模型的控制。感知任务可以使用多层简单的非线性变换（深度学习）来处理，而控制任务通常需要更复杂的模型，如隐马尔可夫模型和卡尔曼滤波器 [35，74]。为了在感知任务和控制任务之间实现有效的迭代过程，我们需要在它们之间进行双向信息交换。感知组件将是控制组件估计其状态的基础，另一方面，具有内置动态模型的控制组件将能够通过颠倒感知过程来预测未来轨迹（图像）[125]。

作为这一方向的开创性工作之一，[125] 将这一任务作为表征学习问题来提出，并提出了一个称为嵌入到控制的模型，以考虑表征学习过程中的上述反馈回路。本质上，目标是学习 (1) 从原始图像/视频捕获语义信息和 (2) 在状态空间中保持局部线性以便于控制的表示。如果没有 `贝叶斯深度学习` 框架，这是不可能的，因为感知组件保证第一个子目标，而特定于任务的组件保证第二个子目标。下面我们从随机最优控制的一些基础知识开始，然后介绍基于 `贝叶斯深度学习` 的表示学习模型。

#### 6.5.3.1 随机最优控制（Stochastic Optimal Control）

#### 6.5.3.2 基于 `贝叶斯深度学习` 的控制表示学习（ `贝叶斯深度学习` -Based Representation Learning for Control）

#### 6.5.3.3 基于随机梯度变分贝叶斯的学习（Learning Using Stochastic Gradient Variational Bayes）

#### 6.5.3.4 讨论

上面的示例模型演示了 `贝叶斯深度学习` 学习满足特定领域需求的表示的能力。在控制的情况下，我们感兴趣的是学习表示法，这种表示法可以从原始输入中捕获语义信息，并在系统状态空间中保持局部线性。

为了实现这一目标，基于 `贝叶斯深度学习` 的模型由两个组件组成，一个是用于查看实时视频的感知组件，另一个是用于推断动态系统状态的控制（特定于任务的）组件。系统的推理基于来自感知组件的映射状态和映射置信度，并且反过来，控制组件发送的控制信号将影响感知组件接收的实况视频。只有当两个组件在统一的概率框架内交互工作时，模型才能充分发挥其潜力，获得最佳的控制性能。

注意，上述基于动态链接库的控制模型使用了与 5.1 节和 5.2 节不同的信息交换机制：它遵循 VAE 机制，并使用神经网络分别参数化铰链变量的均值和协方差（例如，在编码模型中，铰链变量 zt∼N(µt，diag(σ2t))，其中µt 和σ是如公式 (19) 中参数化的感知变量），这比 5.1 节中的 cdl 和 cdr 等模型更灵活（具有更多自由参数。请注意，此基于 `贝叶斯深度学习` 的控制模型是一个 LV 模型，如表 1 所示，由于假设协方差为对角线，因此该模型仍满足第 4.2 节中的独立性要求。

------------------

前面两小节主要谈论 `贝叶斯深度学习` 在监督学习与无监督学习的应用，该节主要关注另外一个领域：representation learning。用控制问题为例。

Stochastic Optimal Control：在该节，我们考虑一个未知动态系统的随机最优控制问题，在 `贝叶斯深度学习` 的框架下解决的具体过程如下：

![图片](https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfp0G9xjCH5OudvPdPBngyxtbGibHAibQpggA6DBFVjxQT29Wuwibic3xq94gib96YOT65TgwuGRAc3Uibrw/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

 `贝叶斯深度学习` -Based Representation Learning for Control：为了能够优化上述问题，有三个关键的部分，具体如下：

![图片](https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfp0G9xjCH5OudvPdPBngyxtGvYFEhiaKNpCrbKIbWoZVDD50CNETw5JknfRibu50UIcHAd8EEZfnu3w/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

Learning Using Stochastic Gradient Variational Bayes：该模型的损失函数是如下这种形式：

![图片](https://mmbiz.qpic.cn/sz_mmbiz_jpg/gYUsOT36vfp0G9xjCH5OudvPdPBngyxtaRBDJkqqRCap5YZe64hsT3uNcog57BUFmjp5qPEQiaQcjjrEOPmOVsA/640?wx_fmt=jpeg&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

在控制的问题中，我们通常希望能够从原始输入中获取语义信息，并在系统状态空间中保持局部线性。而 `贝叶斯深度学习` 的框架正好适用该点，两个组件分别能完成不同的工作：感知模块可以捕获 live video，而任务模块可以推断动态系统的状态。

------------------------

### 6.5.4 其他贝叶斯深度学习的应用

 `贝叶斯深度学习` 在有监督学习、无监督学习和表征学习中得到了广泛的应用，如推荐系统、主题模型和控制。在本节中，我们将简要讨论其他几个可以从 `贝叶斯深度学习` 中受益的应用程序。

#### 6.5.4.1 链接预测

链接预测长期以来一直是网络分析中的核心问题，最近随着 `贝叶斯深度学习` 和深度神经网络带来的新进展引起了人们越来越多的兴趣。[120] 提出了第一个基于 `贝叶斯深度学习` 的链接预测模型，称为关系型深度学习 (RDL)。石墨 [32] 使用基于图形卷积网络 (GCN) 的感知组件扩展了 RDL[59]。[75] 结合经典的随机区块模型`[82]` （作为特定于任务的组件）和基于 GCN 的感知组件，在具有报告的最先进的链接预测性能的图中联合建模潜在的社区结构和链接生成。

#### 6.5.4.2 自然语言处理

除了第 5.2 节中讨论的主题建模之外， `贝叶斯深度学习` 通常也对自然语言处理有用。例如，[77] 和 [69] 建立在 `贝叶斯深度学习` 原则之上，以定义语言修订过程。这些模型通常包括基于 `RNN` 的感知组件和连接输入和输出序列的相对简单的特定于任务的组件。

#### 6.5.4.3 计算机视觉

在无监督学习环境中， `贝叶斯深度学习` 对于计算机视觉特别强大。这是因为在 `贝叶斯深度学习` 框架中，可以清楚地定义场景中的对象如何从诸如计数、位置和内容等各种因素生成的生成过程 [20]。感知组件通常采用概率神经网络的形式，可以专注于对原始图像的视觉特征进行建模，而特定于任务的组件处理图像中对象的各种属性之间的条件依赖关系。在这个方向上一个值得注意的工作是注意、推断、重复（空气）[20]，其中特定于任务的组件涉及关于每个对象的位置、规模、外观和存在（这与对象计数相关）的潜在变量。在 AIR 之后，提出了诸如 Fast Air[105] 和 Sequential Air[60] 等变体，以提高其计算效率和性能。除了无监督学习之外， `贝叶斯深度学习` 还可用于监督学习任务，例如视频 [102] 中的动作识别，其中使用特定于任务的组件对不同动作之间的条件依赖性进行建模。

#### 6.5.4.4 语音

在语音识别和合成领域，研究人员也一直在采用 `贝叶斯深度学习` 框架来提高准确性和可解释性。例如，分解后的分层 V AE[47，48] 将 V `AE` 与分解后的潜变量模型（表示为`概率图模型`) 组合，以在非监督设置之后学习语音数据中的不同潜在因素。类似地，高斯混合 V AE[49] 使用高斯混合模型作为特定于任务的分量来实现从文本中可控的语音合成。在语音识别方面，递归泊松处理单元 (RPPU)[51] 改为采用不同形式的特定于任务的组件；它们使用随机过程（即，泊松过程）作为特定于任务的组件来对音素之间的边界进行建模，并且成功地实现了显著较低的语音识别的单词错误率 (WER)。同样，深度图随机过程 (DGP)[52] 作为另一种随机过程对图进行操作，对话语之间的关系结构进行建模，进一步提高了语音识别的性能。

#### 6.5.4.5 时间序列预测

时间序列预测是经济学、统计学和机器学习中一个长期存在的核心问题 [36]。它在多个领域有着广泛的应用。例如，对区域能源消费的准确预测可以为优化能源发电和配置提供有价值的指导。在电子商务中，零售商依靠需求预测来决定何时何地补充供应，从而避免商品脱销，并保证客户最快的送货速度。在新冠肺炎这样的大流行期间，获得对医院工作量和医疗供应需求的合理预测，以便在全国范围内最佳配置资源，这一点至关重要。不用说，一个理想的预测模型既需要对高维数据进行有效处理，也需要对不同的随机变量（无论是观测到的还是潜在的）进行复杂的建模。基于 `贝叶斯深度学习` 的预测模型 [21，27，90,124] 通过基于 `RNN` 的感知组件和处理不同变量之间的条件依赖关系的特定任务组件来实现这些，显示出与以前的非 `贝叶斯深度学习` 预测模型相比有实质性的改进。

#### 6.5.4.6 医疗保健

在与医疗保健相关的应用 [91] 中，通常希望将人类知识融入模型中，以提高性能，或者更重要的是提高可解释性。当模型用于表达不足的数据时，确保模型的稳健性也是至关重要的。因此， `贝叶斯深度学习` 提供了一个统一的框架来满足所有这些要求：(1) 由于其贝叶斯性质，它可以施加适当的先验，并执行贝叶斯模型平均，以提高鲁棒性；(2) 其特定于任务的组件可以在必要时自然地表示和纳入人类知识；(3) 模型的联合训练为其两个组件提供了可解释性。例如，[38] 提出了一个深度泊松因子模型，该模型本质上是层层叠加的泊松因子模型，用于分析电子病历。[110] 建立了具有实验特异性先验（知识）的 `贝叶斯深度学习模型` ，以控制研究分析中的误发现率，并将其应用于抗癌药物筛选。[61] 开发了深度非线性状态空间模型，并展示了它们在处理电子健康记录和执行反事实推理方面的有效性。上述 `贝叶斯深度学习模型` 中的特定于任务的组件全部采用典型贝叶斯网络的形式（如第 4.4.1 节所述）。相比之下，[117] 建议使用双向推理网络（本质上是一类深度贝叶斯网络）作为任务特定的组件（如第 4.4.2 节所述）。这实现了贝叶斯网络的每个条件分布中的深度非线性结构，并提高了诸如健康概况等应用的性能。

## 6.6 结论与展望

 `贝叶斯深度学习` 致力于将`概率图模型`和 NN 的优点有机地结合在一个单一的原则性概率框架中。在这次调查中，我们发现了这一趋势，并回顾了最近的工作。 `贝叶斯深度学习模型` 由感知组件和特定于任务的组件组成；因此，我们分别研究了过去几年开发的这两个组件的不同实例，并详细讨论了不同的变体。为了学习 `贝叶斯深度学习` 中的参数，已经提出了几种算法，从块坐标下降算法、贝叶斯条件密度滤波算法、随机梯度恒温器算法到随机梯度变分贝叶斯算法。

 `贝叶斯深度学习` 既从`概率图模型`的成功中获得灵感，也从最近在深度学习方面有希望的进展中获得灵感和人气。由于现实世界中的许多任务既涉及对高维信号（如图像和视频）的有效感知，又涉及对随机变量的概率推理，因此 `贝叶斯深度学习` 成为利用神经网络的感知能力和`概率图模型`的（条件和因果）推理能力的自然选择。在过去的几年里， `贝叶斯深度学习` 已经在推荐系统、主题模型、随机最优控制、计算机视觉、自然语言处理、医疗保健等领域得到了成功的应用。在未来，我们可以期待对现有应用进行更深入的研究，以及对更复杂的任务进行更深入的探索。此外，高效神经网络 ( `贝叶斯深度学习` 的感知成分）的最新进展也为进一步提高 `贝叶斯深度学习` 的可扩展性奠定了基础。

## 参考文献

[1] Gediminas Adomavicius and YoungOk Kwon. Improving aggregate recommendation diversity using ranking-based techniques. TKDE, 24(5):896–911,
2012.

[2] Anoop Korattikara Balan, Vivek Rathod, Kevin P Murphy, and Max Welling. Bayesian dark knowledge. In NIPS, pages 3420–3428, 2015.

[3] Ilaria Bartolini, Zhenjie Zhang, and Dimitris Papadias. Collaborative filtering with personalized skylines. TKDE, 23(2):190–203, 2011.

[4] Yoshua Bengio, Li Yao, Guillaume Alain, and Pascal Vincent. Generalized denoising auto-encoders as generative models. In NIPS, pages 899–907,2013.

[5] Christopher M. Bishop. Pattern Recognition and Machine Learning. Springer-Verlag New York, Inc., Secaucus, NJ, USA, 2006.

[6] David Blei and John Lafferty. Correlated topic models. NIPS, 18:147, 2006.

[7] David M Blei and John D Lafferty. Dynamic topic models. In ICML, pages 113–120. ACM, 2006.

[8] David M Blei, Andrew Y Ng, and Michael I Jordan. Latent Dirichlet allocation. JMLR, 3:993–1022, 2003.

[9] Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra. Weight uncertainty in neural network. In ICML, pages 1613–1622,2015.

[10] Hervé Bourlard and Yves Kamp. Auto-association by multilayer perceptrons and singular value decomposition. Biological cybernetics, 59(4-5):291–294,1988.

[11] Yuri Burda, Roger B. Grosse, and Ruslan Salakhutdinov. Importance weighted autoencoders. In ICLR, 2016.

[12] Yi Cai, Ho-fung Leung, Qing Li, Huaqing Min, Jie Tang, and Juanzi Li. Typicality-based collaborative filtering recommendation. TKDE, 26(3):766–779,2014.

[13] Minmin Chen, Kilian Q Weinberger, Fei Sha, and Yoshua Bengio. Marginalized denoising auto-encoders for nonlinear representations. In ICML,pages 1476–1484, 2014.

[14] Minmin Chen, Zhixiang Eddie Xu, Kilian Q. Weinberger, and Fei Sha. Marginalized denoising autoencoders for domain adaptation. In ICML, 2012.

[15] Tianqi Chen, Emily B. Fox, and Carlos Guestrin. Stochastic gradient Hamiltonian Monte Carlo. In ICML, pages 1683–1691, 2014.

[16] Kyunghyun Cho, Bart van Merrienboer, cCaglar Gülccehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. Learning phrase representations using `RNN` encoder-decoder for statistical machine translation. In EMNLP, pages 1724–1734, 2014.

[17] Junyoung Chung, Kyle Kastner, Laurent Dinh, Kratarth Goel, Aaron C. Courville, and Yoshua Bengio. A recurrent latent variable model for sequential data. In NIPS, pages 2980–2988, 2015.

[18] Yulai Cong, Bo Chen, Hongwei Liu, and Mingyuan Zhou. Deep latent dirichlet allocation with topic-layer-adaptive stochastic gradient riemannian `MCMC` . In ICML, pages 864–873, 2017.

[19] Andreas Doerr, Christian Daniel, Martin Schiegg, Duy Nguyen-Tuong, Stefan Schaal, Marc Toussaint, and Sebastian Trimpe. Probabilistic recurrent state-space models. In ICML, pages 1279–1288, 2018.

[20] S. M. Ali Eslami, Nicolas Heess, Theophane Weber, Yuval Tassa, David Szepesvari, Koray Kavukcuoglu, and Geoffrey E. Hinton. Attend, infer, repeat: Fast scene understanding with generative models. In NIPS, pages 3225–3233, 2016.

[21] Valentin Flunkert, David Salinas, and Jan Gasthaus. Deepar: Probabilistic forecasting with autoregressive recurrent networks. CoRR, abs/1704.04110,2017.

[22] Yarin Gal and Zoubin Ghahramani. Dropout as a Bayesian approximation: Insights and applications. In Deep Learning Workshop, ICML, 2015.

[23] M. J. F. Gales and S. S. Airey. Product of Gaussians for speech recognition. CSL, 20(1):22–40, 2006.

[24] Zhe Gan, Changyou Chen, Ricardo Henao, David E. Carlson, and Lawrence Carin. Scalable deep Poisson factor analysis for topic modeling. In ICML, pages 1823–1832, 2015.

[25] Zhe Gan, Ricardo Henao, David E. Carlson, and Lawrence Carin. Learning deep sigmoid belief networks with data augmentation. In AISTATS, 2015.

[26] Jochen Gast and Stefan Roth. Lightweight probabilistic deep networks. In CVPR, pages 3369–3378, 2018.

[27] Jan Gasthaus, Konstantinos Benidis, Yuyang Wang, Syama Sundar Rangapuram, David Salinas, Valentin Flunkert, and Tim Januschowski. Probabilistic forecasting with spline quantile function rnns. In AISTATS, pages 1901–1910, 2019.

[28] Kostadin Georgiev and Preslav Nakov. A non-iid framework for collaborative filtering with restricted Boltzmann machines. In ICML, pages 1148–1156, 2013.

[29] Ian Goodfellow, Yoshua Bengio, and Aaron Courville. Deep Learning. Book in preparation for MIT Press, 2016.

[30] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In NIPS, pages 2672–2680, 2014.

[31] Alex Graves. Practical variational inference for neural networks. In NIPS, pages 2348–2356, 2011.

[32] Aditya Grover, Aaron Zweig, and Stefano Ermon. Graphite: Iterative generative modeling of graphs. In ICML, pages 2434–2444, 2019.

[33] A.K. Gupta and D.K. Nagar. Matrix Variate Distributions. Chapman & Hall/CRC Monographs and Surveys in Pure and Applied Mathematics. Chapman & Hall, 2000.

[34] Danijar Hafner, Timothy P. Lillicrap, Ian Fischer, Ruben Villegas, David Ha, Honglak Lee, and James Davidson. Learning latent dynamics for planning from pixels. In ICML, pages 2555–2565, 2019.

[35] Jeff Harrison and Mike West. Bayesian Forecasting & Dynamic Models. Springer, 1999.

[36] Andrew C Harvey. Forecasting, structural time series models and the Kalman filter. Cambridge university press, 1990.

[37] Hao He, Hao Wang, Guang-He Lee, and Yonglong Tian. Probgan: Towards probabilistic GAN with theoretical guarantees. In ICLR, 2019.

[38] Ricardo Henao, James Lu, Joseph E. Lucas, Jeffrey M. Ferranti, and Lawrence Carin. Electronic health record analysis via deep poisson factor models. JMLR, 17:186:1–186:32, 2016.

[39] José Miguel Hernández-Lobato and Ryan Adams. Probabilistic backpropagation for scalable learning of bayesian neural networks. In ICML, pages 1861–1869, 2015.

[40] Geoffrey E. Hinton. Training products of experts by minimizing contrastive divergence. Neural Computation, 14(8):1771–1800, 2002.

[41] Geoffrey E. Hinton. Training products of experts by minimizing contrastive divergence. Neural Computation, 14(8):1771–1800, 2002.

[42] Geoffrey E Hinton and Drew Van Camp. Keeping the neural networks simple by minimizing the description length of the weights. In COLT, pages 5–13, 1993.

[43] Geoffrey E Hinton and Richard S Zemel. Autoencoders, minimum description length, and Helmholtz free energy. NIPS, pages 3–3, 1994.

[44] Matthew Hoffman, Francis R Bach, and David M Blei. Online learning for latent Dirichlet allocation. In NIPS, pages 856–864, 2010.

[45] Matthew D. Hoffman, David M. Blei, Chong Wang, and John William Paisley. Stochastic variational inference. JMLR, 14(1):1303–1347, 2013.
[46] Mark F. Hornick and Pablo Tamayo. Extending recommender systems for disjoint user/item sets: The conference recommendation problem. TKDE, 24(8):1478–1490, 2012.

[47] Wei-Ning Hsu and James R. Glass. Scalable factorized hierarchical variational autoencoder training. In INTERSPEECH, pages 1462–1466, 2018. 

[48] Wei-Ning Hsu, Yu Zhang, and James R. Glass. Unsupervised learning of disentangled and interpretable representations from sequential data. In NIPS, pages 1878–1889, 2017.

[49] Wei-Ning Hsu, Yu Zhang, Ron J. Weiss, Heiga Zen, Yonghui Wu, Yuxuan Wang, Yuan Cao, Ye Jia, Zhifeng Chen, Jonathan Shen, Patrick Nguyen, and Ruoming Pang. Hierarchical generative modeling for controllable speech synthesis. In ICLR, 2019.

[50] Yifan Hu, Yehuda Koren, and Chris Volinsky. Collaborative filtering for implicit feedback datasets. In ICDM, pages 263–272, 2008.

[51] Hengguan Huang, Hao Wang, and Brian Mak. Recurrent poisson process unit for speech recognition. In AAAI, pages 6538–6545, 2019.

[52] Hengguan Huang, Fuzhao Xue, Hao Wang, and Ye Wang. Deep graph random process for relational-thinking-based speech recognition. In ICML, 2020.

[53] David H Hubel and Torsten N Wiesel. Receptive fields and functional architecture of monkey striate cortex. The Journal of physiology, 195(1):215–243, 1968.

[54] Finn V Jensen et al. An introduction to Bayesian networks, volume 210. UCL press London, 1996.

[55] Michael I. Jordan, Zoubin Ghahramani, Tommi Jaakkola, and Lawrence K. Saul. An introduction to variational methods for graphical models. Machine Learning, 37(2):183–233, 1999.

[56] Nal Kalchbrenner, Edward Grefenstette, and Phil Blunsom. A convolutional neural network for modelling sentences. ACL, pages 655–665, 2014.

[57] Maximilian Karl, Maximilian Sölch, Justin Bayer, and Patrick van der Smagt. Deep variational bayes filters: Unsupervised learning of state space models from raw data. In ICLR, 2017.

[58] Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114, 2013.

[59] Thomas N Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907, 2016.

[60] Adam R. Kosiorek, Hyunjik Kim, Yee Whye Teh, and Ingmar Posner. Sequential attend, infer, repeat: Generative modelling of moving objects. In NIPS, pages 8615–8625, 2018.

[61] Rahul G. Krishnan, Uri Shalit, and David A. Sontag. Structured inference networks for nonlinear state space models. In AAAI, pages 2101–2109, 2017.

[62] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolutional neural networks. In NIPS, pages 1097–1105, 2012.

[63] Y. LeCun. Modeles connexionnistes de l’apprentissage (connectionist learning models). PhD thesis, Université P. et M. Curie (Paris 6), June 1987.

[64] Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278–2324, 1998.

[65] Honglak Lee, Roger Grosse, Rajesh Ranganath, and Andrew Y Ng. Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations. In ICML, pages 609–616, 2009.

[66] Sheng Li, Jaya Kawale, and Yun Fu. Deep collaborative filtering via marginalized denoising auto-encoder. In CIKM, pages 811–820, 2015.

[67] Wu-Jun Li and Dit-Yan Yeung. Relation regularized matrix factorization. In IJCAI, 2009.

[68] Xiaopeng Li and James She. Collaborative variational autoencoder for recommender systems. In KDD, pages 305–314, 2017.

[69] Yi Liao, Lidong Bing, Piji Li, Shuming Shi, Wai Lam, and Tong Zhang. Quase: Sequence editing under quantifiable guidance. In EMNLP, pages 3855–3864, 2018.

[70] Nathan Nan Liu, Xiangrui Meng, Chao Liu, and Qiang Yang. Wisdom of the better few: cold start recommendation via representative based rating elicitation. In RecSys, pages 37–44, 2011.

[71] Zhongqi Lu, Zhicheng Dou, Jianxun Lian, Xing Xie, and Qiang Yang. Content-based collaborative filtering for news topic recommendation. In AAAI, pages 217–223, 2015.

[72] JC MacKay David. A practical Bayesian framework for backprop networks. Neural computation, 1992.

[73] Wesley J Maddox, Pavel Izmailov, Timur Garipov, Dmitry P Vetrov, and Andrew Gordon Wilson. A simple baseline for bayesian uncertainty in deep learning. In NIPS, pages 13132–13143, 2019.

[74] Takamitsu Matsubara, Vicencc Gómez, and Hilbert J. Kappen. Latent Kullback Leibler control for continuous-state systems using probabilistic graphical models. In UAI, pages 583–592, 2014.

[75] Nikhil Mehta, Lawrence Carin, and Piyush Rai. Stochastic blockmodels meet graph neural networks. In ICML, pages 4466–4474, 2019.

[76] Abdel-rahman Mohamed, Tara N. Sainath, George E. Dahl, Bhuvana Ramabhadran, Geoffrey E. Hinton, and Michael A. Picheny. Deep belief networks using discriminative features for phone recognition. In ICASSP, pages 5060–5063, 2011.

[77] Jonas Mueller, David K. Gifford, and Tommi S. Jaakkola. Sequence to better sequence: Continuous revision of combinatorial structures. In ICML, pages 2536–2544, 2017.

[78] Kevin P Murphy. Machine learning: a probabilistic perspective. MIT press, 2012.

[79] Radford M. Neal. Connectionist learning of belief networks. Artif. Intell., 56(1):71–113, 1992.

[80] Radford M Neal. Bayesian learning for neural networks. PhD thesis, University of Toronto, 1995.

[81] Radford M Neal et al. Mcmc using hamiltonian dynamics. Handbook of markov chain monte carlo, 2(11):2, 2011.

[82] Krzysztof Nowicki and Tom A B Snijders. Estimation and prediction for stochastic blockstructures. JASA, 96(455):1077–1087, 2001.

[83] Takahiro Omi, Naonori Ueda, and Kazuyuki Aihara. Fully neural network based model for general temporal point processes. In NIPS, pages
2120–2129, 2019.

[84] Aäron Van Den Oord, Sander Dieleman, and Benjamin Schrauwen. Deep content-based music recommendation. In NIPS, pages 2643–2651, 2013.

[85] Yoon-Joo Park. The adaptive clustering method for the long tail problem of recommender systems. TKDE, 25(8):1904–1915, 2013.

[86] Ian Porteous, David Newman, Alexander Ihler, Arthur Asuncion, Padhraic Smyth, and Max Welling. Fast collapsed gibbs sampling for latent Dirichlet allocation. In KDD, pages 569–577, 2008.

[87] Janis Postels, Francesco Ferroni, Huseyin Coskun, Nassir Navab, and Federico Tombari. Sampling-free epistemic uncertainty estimation using approximated variance propagation. In ICCV, pages 2931–2940, 2019.

[88] Christopher Poultney, Sumit Chopra, Yann L Cun, et al. Efficient learning of sparse representations with an energy-based model. In NIPS, pages 1137–1144, 2006.

[89] Sanjay Purushotham, Yan Liu, and C.-C. Jay Kuo. Collaborative topic regression with social matrix factorization for recommendation systems. In ICML, pages 759–766, 2012.

[90] Syama Sundar Rangapuram, Matthias W. Seeger, Jan Gasthaus, Lorenzo Stella, Yuyang Wang, and Tim Januschowski. Deep state space models for time series forecasting. In NIPS, pages 7796–7805, 2018.

[91] Daniele Ravì, Charence Wong, Fani Deligianni, Melissa Berthelot, Javier Andreu-Perez, Benny Lo, and Guang-Zhong Yang. Deep learning for health informatics. IEEE journal of biomedical and health informatics, 21(1):4–21, 2016.

[92] Francesco Ricci, Lior Rokach, and Bracha Shapira. Introduction to Recommender Systems Handbook. Springer, 2011.

[93] Salah Rifai, Pascal Vincent, Xavier Muller, Xavier Glorot, and Yoshua Bengio. Contractive auto-encoders: Explicit invariance during feature extraction. In ICML, pages 833–840, 2011.

[94] Sheldon M Ross, John J Kelly, Roger J Sullivan, William James Perry, Donald Mercer, Ruth M Davis, Thomas Dell Washburn, Earl V Sager, Joseph B Boyce, and Vincent L Bristow. Stochastic processes, volume 2. Wiley New York, 1996.

[95] Tara N. Sainath, Brian Kingsbury, Vikas Sindhwani, Ebru Arisoy, and Bhuvana Ramabhadran. Low-rank matrix factorization for deep neural network training with high-dimensional output targets. In ICASSP, pages 6655–6659, 2013.

[96] Ruslan Salakhutdinov and Andriy Mnih. Probabilistic matrix factorization. In NIPS, pages 1257–1264, 2007. 

[97] Ruslan Salakhutdinov and Andriy Mnih. Bayesian probabilistic matrix factorization using markov chain monte carlo. In ICML, pages 880–887, 2008.

[98] Ruslan Salakhutdinov, Andriy Mnih, and Geoffrey E. Hinton. Restricted Boltzmann machines for collaborative filtering. In ICML, pages 791–798, 2007.

[99] Oleksandr Shchur, Marin Bilos, and Stephan Günnemann. Intensity-free learning of temporal point processes. 2019.

[100] Alexander Shekhovtsov and Boris Flach. Feed-forward propagation in probabilistic neural networks with categorical and max layers. In ICLR, 2019.

[101] Jonathan R Shewchuk. An introduction to the conjugate gradient method without the agonizing pain. Technical report, Carnegie Mellon University, Pittsburgh, PA, USA, 1994.

[102] Gunnar A. Sigurdsson, Santosh Kumar Divvala, Ali Farhadi, and Abhinav Gupta. Asynchronous temporal fields for action recognition. In CVPR, pages 5650–5659, 2017.

[103] Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. Dropout: A simple way to prevent neural networks from overfitting. JMLR, 15(1):1929–1958, 2014.

[104] Nitish Srivastava and Russ R Salakhutdinov. Multimodal learning with deep boltzmann machines. In NIPS, pages 2222–2230, 2012.

[105] Karl Stelzner, Robert Peharz, and Kristian Kersting. Faster attend-infer-repeat with tractable probabilistic models. In ICML, pages 5966–5975, 2019.

[106] Robert S Strichartz. A Guide to Distribution Theory and Fourier Transforms. World Scientific, 2003.

[107] Jiahao Su, Milan Cvitkovic, and Furong Huang. Sampling-free learning of bayesian quantized neural networks. 2020.

[108] Ilya Sutskever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence learning with neural networks. In NIPS, pages 3104–3112, 2014.

[109] Jinhui Tang, Guo-Jun Qi, Liyan Zhang, and Changsheng Xu. Cross-space affinity learning with its application to movie recommendation. IEEE Transactions on Knowledge and Data Engineering, 25(7):1510–1519, 2013.

[110] Wesley Tansey, Yixin Wang, David M. Blei, and Raul Rabadan. Black box FDR. In ICML, pages 4874–4883, 2018.

[111] Pascal Vincent, Hugo Larochelle, Isabelle Lajoie, Yoshua Bengio, and Pierre-Antoine Manzagol. Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion. JMLR, 11:3371–3408, 2010.

[112] Chong Wang and David M. Blei. Collaborative topic modeling for recommending scientific articles. In KDD, pages 448–456, 2011.

[113] Chong Wang, David M. Blei, and David Heckerman. Continuous time dynamic topic models. In UAI, pages 579–586, 2008.

[114] Hao Wang. Bayesian Deep Learning for Integrated Intelligence: Bridging the Gap between Perception and Inference. PhD thesis, Hong Kong University of Science and Technology, 2017.

[115] Hao Wang, Binyi Chen, and Wu-Jun Li. Collaborative topic regression with social regularization for tag recommendation. In IJCAI, pages 2719–2725, 2013.

[116] Hao Wang and Wu-Jun Li. Relational collaborative topic regression for recommender systems. TKDE, 27(5):1343–1355, 2015.

[117] Hao Wang, Chengzhi Mao, Hao He, Mingmin Zhao, Tommi S. Jaakkola, and Dina Katabi. Bidirectional inference networks: A class of deep bayesian networks for health profiling. In AAAI, pages 766–773, 2019.

[118] Hao Wang, Xingjian Shi, and Dit-Yan Yeung. Relational stacked denoising autoencoder for tag recommendation. In AAAI, pages 3052–3058, 2015.

[119] Hao Wang, Xingjian Shi, and Dit-Yan Yeung. Natural-parameter networks: A class of probabilistic neural networks. In NIPS, pages 118–126, 2016.

[120] Hao Wang, Xingjian Shi, and Dit-Yan Yeung. Relational deep learning: A deep latent variable model for link prediction. In AAAI, pages 2688–2694 2017.

[121] Hao Wang, Naiyan Wang, and Dit-Yan Yeung. Collaborative deep learning for recommender systems. In KDD, pages 1235–1244, 2015.

[122] Hao Wang, SHI Xingjian, and Dit-Yan Yeung. Collaborative recurrent autoencoder: Recommend while learning to fill in the blanks. In NIPS, pages 415–423, 2016.

[123] Xinxi Wang and Ye Wang. Improving content-based and hybrid music recommendation using deep learning. In ACM MM, pages 627–636, 2014.

[124] Yuyang Wang, Alex Smola, Danielle C. Maddix, Jan Gasthaus, Dean Foster, and Tim Januschowski. Deep factors for forecasting. In ICML, pages 6607–6617, 2019.

[125] Manuel Watter, Jost Springenberg, Joschka Boedecker, and Martin Riedmiller. Embed to control: A locally linear latent dynamics model for control from raw images. In NIPS, pages 2728–2736, 2015.

[126] Yan Zheng Wei, Luc Moreau, and Nicholas R. Jennings. Learning users’ interests by quality classification in market-based recommender systems. TKDE, 17(12):1678–1688, 2005.

[127] Max Welling and Yee Whye Teh. Bayesian learning via stochastic gradient langevin dynamics. In ICML, pages 681–688, 2011.

[128] Andrew Gordon Wilson. The case for bayesian deep learning. arXiv preprint arXiv:2001.10995, 2020.

[129] Zichao Yang, Zhiting Hu, Ruslan Salakhutdinov, and Taylor Berg-Kirkpatrick. Improved variational autoencoders for text modeling using dilated convolutions. In ICML, pages 3881–3890, 2017.

[130] Ghim-Eng Yap, Ah-Hwee Tan, and HweeHwa Pang. Discovering and exploiting causal dependencies for robust mobile context-aware recommenders. TKDE, 19(7):977–992, 2007.

[131] Haochao Ying, Liang Chen, Yuwen Xiong, and Jian Wu. Collaborative deep ranking: a hybrid pair-wise recommendation algorithm with implicit feedback. In PAKDD, 2016.

[132] Fuzheng Zhang, Nicholas Jing Yuan, Defu Lian, Xing Xie, and Wei-Ying Ma. Collaborative knowledge base embedding for recommender systems. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining, pages 353–362. ACM, 2016.

[133] He Zhao, Lan Du, Wray L. Buntine, and Mingyuan Zhou. Dirichlet belief networks for topic structure learning. In NIPS, pages 7966–7977, 2018. 

[134] Vincent Wenchen Zheng, Bin Cao, Yu Zheng, Xing Xie, and Qiang Yang. Collaborative filtering meets mobile recommendation: A user-centered approach. In AAAI, 2010.

[135] Mingyuan Zhou and Lawrence Carin. Negative binomial process count and mixture modeling. IEEE Trans. Pattern Anal. Mach. Intell., 37(2):307–320, 2015.

[136] Mingyuan Zhou, Lauren Hannah, David B. Dunson, and Lawrence Carin. Beta-negative binomial process and Poisson factor analysis. In AISTATS, pages 1462–1471, 2012.
